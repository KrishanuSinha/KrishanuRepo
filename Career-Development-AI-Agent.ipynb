{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aac2acb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, json\n",
    "from dotenv import load_dotenv\n",
    "import boto3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "144b6544",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.40.2\n"
     ]
    }
   ],
   "source": [
    "print(boto3.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "88635db9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load AWS credentials from .env file\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bbfe19a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "aws_access_key_id = os.getenv(\"AWS_ACCESS_KEY_ID\")\n",
    "aws_secret_access_key = os.getenv(\"AWS_SECRET_ACCESS_KEY\")\n",
    "aws_session_token = os.getenv(\"AWS_SESSION_TOKEN\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cb02a1eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the AWS region (change as needed, e.g., 'us-east-1')\n",
    "aws_region = 'us-east-1'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9b09fe4",
   "metadata": {},
   "source": [
    "### Setup AWS Clients and Model IDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "900c6e7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import boto3\n",
    "import json\n",
    "\n",
    "region = \"us-west-2\"  \n",
    "job_kb_id = \"9PFZZ5FEIF\"  \n",
    "job_model_id = \"us.anthropic.claude-3-7-sonnet-20250219-v1:0\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a098e83f",
   "metadata": {},
   "source": [
    "### LLM Query Analyzer Node (Intent Classification)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cc3393ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def llm_query_analyzer(question, model_id=job_model_id, region=region):\n",
    "    \"\"\"\n",
    "    Uses LLM to classify the user query into one or more agent tool intents.\n",
    "    Returns a list of detected intents (e.g., ['job'], ['courses'], etc.).\n",
    "    \"\"\"\n",
    "    prompt = f\"\"\"\n",
    "                Classify the user's query intent(s) as one or more of the following: job, courses, mentoring, objectives.\n",
    "                Respond ONLY with a comma-separated list of intents (e.g., \"job\", \"courses\").\n",
    "                User query:\n",
    "                {question}\n",
    "              \"\"\"\n",
    "    client = boto3.client(\"bedrock-runtime\", region_name=region)\n",
    "    body = {\n",
    "        \"anthropic_version\": \"bedrock-2023-05-31\",\n",
    "        \"messages\": [{\"role\": \"user\", \"content\": prompt}],\n",
    "        \"max_tokens\": 10,\n",
    "        \"temperature\": 0.0\n",
    "    }\n",
    "    response = client.invoke_model(\n",
    "        modelId=model_id,\n",
    "        contentType=\"application/json\",\n",
    "        accept=\"application/json\",\n",
    "        body=json.dumps(body)\n",
    "    )\n",
    "    categories = json.loads(response['body'].read())['content'][0]['text']\n",
    "    # Parse and clean result\n",
    "    return [cat.strip().lower() for cat in categories.split(\",\") if cat.strip()]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e3fcc19",
   "metadata": {},
   "source": [
    "### Courses KB Tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b4bbbaf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CoursesKBTool:\n",
    "    def __init__(self, kb_id, region, model_id):\n",
    "        self.kb_id = kb_id\n",
    "        self.region = region\n",
    "        self.model_id = model_id\n",
    "        self.kb_client = boto3.client('bedrock-agent-runtime', region_name=region)\n",
    "        self.llm_client = boto3.client('bedrock-runtime', region_name=region)\n",
    "\n",
    "    def retrieve_context(self, query_text, extra_context=None):\n",
    "        \"\"\"\n",
    "        Retrieves relevant course documents from KB using collaborative filtering hints\n",
    "        (e.g., if extra_context has skills from a job, use that to filter courses)\n",
    "        \"\"\"\n",
    "        # Collaborative filter: combine user query with job-related skills if present\n",
    "        effective_query = query_text\n",
    "        if extra_context:\n",
    "            effective_query += \"\\n\" + extra_context\n",
    "\n",
    "        response = self.kb_client.retrieve(\n",
    "            knowledgeBaseId=self.kb_id,\n",
    "            retrievalQuery={'text': effective_query}\n",
    "        )\n",
    "        return [\n",
    "            f\"[{i+1}] {doc.get('content', {}).get('text', 'No content')}\"\n",
    "            for i, doc in enumerate(response.get('retrievalResults', []))\n",
    "        ]\n",
    "\n",
    "    def ask_llm(self, context, question):\n",
    "        prompt = f\"\"\"\n",
    "You are a helpful learning advisor who only recommends courses using the context below.\n",
    "If the user's question or skill requirement is not addressed by the provided courses, reply honestly and, if possible, summarize the closest match.\n",
    "\n",
    "Context (LinkedIn/Absorb courses):\n",
    "{context}\n",
    "\n",
    "User question:\n",
    "{question}\n",
    "\n",
    "Please cite which courses you are referencing.\n",
    "\"\"\"\n",
    "        body = {\n",
    "            \"anthropic_version\": \"bedrock-2023-05-31\",\n",
    "            \"messages\": [{\"role\": \"user\", \"content\": prompt}],\n",
    "            \"max_tokens\": 512,\n",
    "            \"temperature\": 0.1\n",
    "        }\n",
    "        response = self.llm_client.invoke_model(\n",
    "            modelId=self.model_id,\n",
    "            contentType=\"application/json\",\n",
    "            accept=\"application/json\",\n",
    "            body=json.dumps(body)\n",
    "        )\n",
    "        return json.loads(response['body'].read())['content'][0]['text']\n",
    "\n",
    "    def run(self, question, extra_context=None):\n",
    "        context_list = self.retrieve_context(question, extra_context=extra_context)\n",
    "        context = \"\\n\".join(context_list) if context_list else \"[No context found]\"\n",
    "        return self.ask_llm(context, question)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cb1bda4",
   "metadata": {},
   "source": [
    "### Job Recommendation Tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "726a0eac",
   "metadata": {},
   "outputs": [],
   "source": [
    "class JobKBTool:\n",
    "    def __init__(self, kb_id, region, model_id):\n",
    "        self.kb_id = kb_id\n",
    "        self.region = region\n",
    "        self.model_id = model_id\n",
    "        self.kb_client = boto3.client('bedrock-agent-runtime', region_name=region)\n",
    "        self.llm_client = boto3.client('bedrock-runtime', region_name=region)\n",
    "\n",
    "    def retrieve_context(self, query_text):\n",
    "        response = self.kb_client.retrieve(\n",
    "            knowledgeBaseId=self.kb_id,\n",
    "            retrievalQuery={'text': query_text}\n",
    "        )\n",
    "        return [\n",
    "            f\"[{i+1}] {doc.get('content', {}).get('text', 'No content')}\"\n",
    "            for i, doc in enumerate(response.get('retrievalResults', []))\n",
    "        ]\n",
    "\n",
    "    def ask_llm(self, context, question):\n",
    "        prompt = f\"\"\"\n",
    "You are a helpful assistant that only answers using the provided job postings context below.\n",
    "If the user's question is not addressed by any of the provided postings, reply honestly that you did not find relevant results, and summarize any closest match if possible.\n",
    "\n",
    "Context:\n",
    "{context}\n",
    "\n",
    "User question:\n",
    "{question}\n",
    "\n",
    "Please cite which postings you are referencing.\n",
    "\"\"\"\n",
    "        body = {\n",
    "            \"anthropic_version\": \"bedrock-2023-05-31\",\n",
    "            \"messages\": [{\"role\": \"user\", \"content\": prompt}],\n",
    "            \"max_tokens\": 512,\n",
    "            \"temperature\": 0.1\n",
    "        }\n",
    "        response = self.llm_client.invoke_model(\n",
    "            modelId=self.model_id,\n",
    "            contentType=\"application/json\",\n",
    "            accept=\"application/json\",\n",
    "            body=json.dumps(body)\n",
    "        )\n",
    "        return json.loads(response['body'].read())['content'][0]['text']\n",
    "\n",
    "    def run(self, question):\n",
    "        # Step 1: Retrieve job postings context from KB\n",
    "        context_list = self.retrieve_context(question)\n",
    "        \n",
    "        if not context_list:\n",
    "            # No results at all → direct to portal\n",
    "            return f\"I couldn't find any job postings related to your request. Please check our internal job portal: https://www.smartrecruiters.com/app/employee-portal/5fa27e743f1d3276c0088aaa/jobs\"\n",
    "        \n",
    "        context = \"\\n\".join(context_list)\n",
    "\n",
    "        # Step 2: Ask LLM to return exact or closest match\n",
    "        prompt = f\"\"\"\n",
    "    You are a job recommendation assistant.\n",
    "    User is asking: \"{question}\"\n",
    "\n",
    "    You have the following job postings:\n",
    "    {context}\n",
    "\n",
    "    Instructions:\n",
    "    1. If a job exactly matches the role in the user's query, return it.\n",
    "    2. If there is no exact match, return the closest technical/developer-related roles.\n",
    "    3. If no relevant matches are found at all, say: \"I couldn't find any job postings related to your request. Please check our internal job portal: https://www.smartrecruiters.com/app/employee-portal/5fa27e743f1d3276c0088aaa/jobs\"\n",
    "    4. Do not invent job postings — only use what's in the context.\n",
    "    \"\"\"\n",
    "        body = {\n",
    "            \"anthropic_version\": \"bedrock-2023-05-31\",\n",
    "            \"messages\": [{\"role\": \"user\", \"content\": prompt}],\n",
    "            \"max_tokens\": 512,\n",
    "            \"temperature\": 0.1\n",
    "        }\n",
    "        response = self.llm_client.invoke_model(\n",
    "            modelId=self.model_id,\n",
    "            contentType=\"application/json\",\n",
    "            accept=\"application/json\",\n",
    "            body=json.dumps(body)\n",
    "        )\n",
    "        return json.loads(response['body'].read())['content'][0]['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29370aa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7077e5ec",
   "metadata": {},
   "source": [
    "### Agent Tool Dispatcher Node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b6f3a861",
   "metadata": {},
   "outputs": [],
   "source": [
    "def agent_tool_dispatcher(intents, question, tool_map):\n",
    "    \"\"\"\n",
    "    Calls the correct tool(s) for each intent.\n",
    "    If both 'job' and 'courses' are in the intents, extract skills from the job tool\n",
    "    and use as collaborative filtering context for the courses tool.\n",
    "    \"\"\"\n",
    "    results = {}\n",
    "    job_tool = tool_map.get(\"job\")\n",
    "    courses_tool = tool_map.get(\"courses\")\n",
    "\n",
    "    job_answer = None\n",
    "    skills_context = None\n",
    "\n",
    "    if \"job\" in intents and job_tool:\n",
    "        # Step 1: Get job posting context\n",
    "        job_answer = job_tool.run(question)\n",
    "        results[\"job\"] = job_answer\n",
    "\n",
    "        # Try to extract skills from job context for collaborative course recommendation\n",
    "        # For now, let's simply use the question itself or a placeholder\n",
    "        # (In production, use NER or another LLM call to extract skill phrases)\n",
    "        skills_context = question  # Replace with actual skills extraction logic if available\n",
    "\n",
    "    if \"courses\" in intents and courses_tool:\n",
    "        # Use collaborative filtering by passing skills_context to the Courses tool\n",
    "        courses_answer = courses_tool.run(question, extra_context=skills_context)\n",
    "        results[\"courses\"] = courses_answer\n",
    "\n",
    "    # You can add similar logic for mentoring/objectives as more KBs come online\n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9ee2a8a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def global_reflexion_node(all_tool_answers, user_query, model_id, region):\n",
    "    \"\"\"\n",
    "    Aggregates answers from all tools and refines them into one cumulative, human-like answer.\n",
    "    \"\"\"\n",
    "    aggregated_context = \"\\n\\n\".join(\n",
    "        f\"{intent.title()} Tool:\\n{answer}\" for intent, answer in all_tool_answers.items()\n",
    "    )\n",
    "    prompt = f\"\"\"\n",
    "You are an assistant that synthesizes answers from multiple tools (Job KB, Courses KB, etc).\n",
    "Your task is to provide a single, clear, and honest response to the user's question by combining the outputs below.\n",
    "\n",
    "If there are no relevant job postings, say so transparently and summarize any related postings if needed.\n",
    "If there are relevant courses, recommend them with context.\n",
    "If neither is found, explain honestly.\n",
    "Do not repeat the same information or cite the same item twice.\n",
    "\n",
    "User question:\n",
    "{user_query}\n",
    "\n",
    "Aggregated tool answers:\n",
    "{aggregated_context}\n",
    "\n",
    "Final response:\n",
    "\"\"\"\n",
    "    client = boto3.client(\"bedrock-runtime\", region_name=region)\n",
    "    body = {\n",
    "        \"anthropic_version\": \"bedrock-2023-05-31\",\n",
    "        \"messages\": [{\"role\": \"user\", \"content\": prompt}],\n",
    "        \"max_tokens\": 512,\n",
    "        \"temperature\": 0.1\n",
    "    }\n",
    "    response = client.invoke_model(\n",
    "        modelId=model_id,\n",
    "        contentType=\"application/json\",\n",
    "        accept=\"application/json\",\n",
    "        body=json.dumps(body)\n",
    "    )\n",
    "    return json.loads(response['body'].read())['content'][0]['text']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbccbf65",
   "metadata": {},
   "source": [
    "### Main Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "552fe95d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User Query: Are there any sales jobs\n",
      "Detected Intents: ['job']\n",
      "\n",
      "===== Cumulative Agent Answer =====\n",
      "\n",
      "# Available Sales Job Opportunities\n",
      "\n",
      "Yes, there are several sales positions currently available across different locations and industries:\n",
      "\n",
      "## Sales Executive Roles\n",
      "- **Sales Executive - Informa Markets Latam** (Mexico City)\n",
      "  - B2B sales position with hybrid work arrangement\n",
      "  - Focuses on client acquisition and relationship management\n",
      "  - Requires a Bachelor's degree, B2B sales experience, and English proficiency\n",
      "\n",
      "- **Sales Executive - Informa Markets** (Hangzhou, China)\n",
      "  - Retail industry position focused on the CBME exhibition\n",
      "  - Involves client development and meeting sales targets\n",
      "  - Requires a Bachelor's degree and at least 1 year of sales experience\n",
      "\n",
      "- **Sales Executive** (Bangkok, Thailand) - Taylor and Francis\n",
      "  - Home-based position with travel requirements\n",
      "  - Promotes online resources to academic markets\n",
      "  - Requires 3+ years sales experience and strong English skills\n",
      "\n",
      "## Specialized Sales Positions\n",
      "- **Business Analyst - Sales** (Shawnee, KS)\n",
      "  - Analytical role supporting sales operations\n",
      "  - Focuses on territory optimization and quota setting\n",
      "  - Requires Excel and Salesforce expertise\n",
      "  - Salary range: $70,000-$75,000\n",
      "\n",
      "- **Retail Relations Manager - Coterie** (New York, NY)\n",
      "  - Leadership role managing retail/buyer acquisition teams\n",
      "  - Focuses on retail partnerships\n",
      "  - Salary range: $76,500-$95,000\n",
      "\n",
      "Would you like more specific information about any of these positions or other types of sales roles?\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"# Available Sales Job Opportunities\\n\\nYes, there are several sales positions currently available across different locations and industries:\\n\\n## Sales Executive Roles\\n- **Sales Executive - Informa Markets Latam** (Mexico City)\\n  - B2B sales position with hybrid work arrangement\\n  - Focuses on client acquisition and relationship management\\n  - Requires a Bachelor's degree, B2B sales experience, and English proficiency\\n\\n- **Sales Executive - Informa Markets** (Hangzhou, China)\\n  - Retail industry position focused on the CBME exhibition\\n  - Involves client development and meeting sales targets\\n  - Requires a Bachelor's degree and at least 1 year of sales experience\\n\\n- **Sales Executive** (Bangkok, Thailand) - Taylor and Francis\\n  - Home-based position with travel requirements\\n  - Promotes online resources to academic markets\\n  - Requires 3+ years sales experience and strong English skills\\n\\n## Specialized Sales Positions\\n- **Business Analyst - Sales** (Shawnee, KS)\\n  - Analytical role supporting sales operations\\n  - Focuses on territory optimization and quota setting\\n  - Requires Excel and Salesforce expertise\\n  - Salary range: $70,000-$75,000\\n\\n- **Retail Relations Manager - Coterie** (New York, NY)\\n  - Leadership role managing retail/buyer acquisition teams\\n  - Focuses on retail partnerships\\n  - Salary range: $76,500-$95,000\\n\\nWould you like more specific information about any of these positions or other types of sales roles?\""
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Instantiate the job and courses tools\n",
    "job_tool = JobKBTool(\n",
    "    kb_id=\"9PFZZ5FEIF\",\n",
    "    region=\"us-west-2\",\n",
    "    model_id=\"us.anthropic.claude-3-7-sonnet-20250219-v1:0\"\n",
    ")\n",
    "courses_tool = CoursesKBTool(\n",
    "    kb_id=\"DENPFPR7CR\",\n",
    "    region=\"us-west-2\",\n",
    "    model_id=\"us.anthropic.claude-3-7-sonnet-20250219-v1:0\"\n",
    ")\n",
    "\n",
    "tool_map = {\n",
    "    \"job\": job_tool,\n",
    "    \"courses\": courses_tool\n",
    "    # Add more tools as needed\n",
    "}\n",
    "\n",
    "def run_agentic_workflow(question):\n",
    "    print(f\"User Query: {question}\")\n",
    "    intents = llm_query_analyzer(question)\n",
    "    print(\"Detected Intents:\", intents)\n",
    "    answers = agent_tool_dispatcher(intents, question, tool_map)\n",
    "    final_answer = global_reflexion_node(\n",
    "        all_tool_answers=answers,\n",
    "        user_query=question,\n",
    "        model_id=job_model_id,   # You can use your preferred LLM\n",
    "        region=region\n",
    "    )\n",
    "    print(\"\\n===== Cumulative Agent Answer =====\\n\")\n",
    "    print(final_answer)\n",
    "    return final_answer\n",
    "\n",
    "# Example multi-intent query\n",
    "user_query = \"Are there any sales jobs\"\n",
    "run_agentic_workflow(user_query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "143b2c82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Connected to aidb database\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SinhaK\\AppData\\Local\\Temp\\ipykernel_25840\\1580065137.py:24: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df_col = pd.read_sql(query_col, conn)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "langchain_pg_collection sample:\n",
      "                             collection_id  \\\n",
      "0     e2ea7251-7d14-421e-83b4-51c8b224f00c   \n",
      "1     e2ea7251-7d14-421e-83b4-51c8b224f00c   \n",
      "2     e2ea7251-7d14-421e-83b4-51c8b224f00c   \n",
      "3     e2ea7251-7d14-421e-83b4-51c8b224f00c   \n",
      "4     e2ea7251-7d14-421e-83b4-51c8b224f00c   \n",
      "...                                    ...   \n",
      "1400  e2ea7251-7d14-421e-83b4-51c8b224f00c   \n",
      "1401  e2ea7251-7d14-421e-83b4-51c8b224f00c   \n",
      "1402  e2ea7251-7d14-421e-83b4-51c8b224f00c   \n",
      "1403  e2ea7251-7d14-421e-83b4-51c8b224f00c   \n",
      "1404  e2ea7251-7d14-421e-83b4-51c8b224f00c   \n",
      "\n",
      "                                              embedding  \\\n",
      "0     [-0.055500098,0.06580695,-0.017995978,-0.03934...   \n",
      "1     [-0.042999007,0.044041406,-0.033617407,-0.0204...   \n",
      "2     [-0.033228796,0.053677283,0.055665333,0.014910...   \n",
      "3     [-0.04324236,0.0514435,0.049703863,0.034047145...   \n",
      "4     [-0.088469006,0.04181069,-0.03438778,-0.029085...   \n",
      "...                                                 ...   \n",
      "1400  [-0.047412284,-0.04378664,-0.04573891,-0.04546...   \n",
      "1401  [-0.046181753,-0.005294152,-0.03756754,-0.0380...   \n",
      "1402  [0.021529865,0.01827535,0.02340747,-0.02753819...   \n",
      "1403  [-0.0053589134,0.05038161,-0.056327265,0.02785...   \n",
      "1404  [-0.013046128,0.041549753,-0.06479783,0.030667...   \n",
      "\n",
      "                                               document  \\\n",
      "0     # Name: Kedar Santosh Prabhu\\n- Name: Kedar Sa...   \n",
      "1     # Name: Patricia Cheong, DES,CASE\\n- Timezone:...   \n",
      "2     # Name: Rich McCarthy\\n- Name: Rich McCarthy\\n...   \n",
      "3     # Name: Rich McCarthy\\n- Timezone: US/Pacific ...   \n",
      "4     # Name: Spencer Smith\\n- Name: Spencer Smith\\n...   \n",
      "...                                                 ...   \n",
      "1400  # Name: Kay Blough\\n- Name: Kay Blough\\n    - ...   \n",
      "1401  # Name: Kay Blough\\n- Timezone: US/Central \\n ...   \n",
      "1402  # Name: David Zoia\\n- Name: David Zoia\\n    - ...   \n",
      "1403  # Name: Hedley Jackson\\n- Name: Hedley Jackson...   \n",
      "1404  # Name: Hedley Jackson\\n- Timezone:  \\n    - L...   \n",
      "\n",
      "                                              cmetadata custom_id  \\\n",
      "0     {'id': '09011957', 'name': 'Kedar Santosh Prab...  09011957   \n",
      "1     {'id': '718008', 'name': 'Patricia Cheong, DES...    718008   \n",
      "2     {'id': '807092', 'name': 'Rich McCarthy', 'own...    807092   \n",
      "3     {'id': '807092', 'name': 'Rich McCarthy', 'own...    807092   \n",
      "4     {'id': '01711318', 'name': 'Spencer Smith', 'o...  01711318   \n",
      "...                                                 ...       ...   \n",
      "1400  {'id': '2005498', 'name': 'Kay Blough', 'owner...   2005498   \n",
      "1401  {'id': '2005498', 'name': 'Kay Blough', 'owner...   2005498   \n",
      "1402  {'id': '01001725', 'name': 'David Zoia', 'owne...  01001725   \n",
      "1403  {'id': '05021372', 'name': 'Hedley Jackson', '...  05021372   \n",
      "1404  {'id': '05021372', 'name': 'Hedley Jackson', '...  05021372   \n",
      "\n",
      "                                      uuid  \n",
      "0     3da443c9-cfae-4b84-9efc-72f621418ab0  \n",
      "1     e1eef846-ecd0-4dba-b282-16a82e4f894f  \n",
      "2     9e2ca4f5-db78-4a58-9154-a537c7529b0a  \n",
      "3     fcaf6777-8701-482e-b1a6-4141dbbcbb86  \n",
      "4     cfb7b1d0-3e2a-4999-8611-b60731f6ca4b  \n",
      "...                                    ...  \n",
      "1400  f81a3444-7f2a-4d4f-9ef5-068de38a4e44  \n",
      "1401  d04c9949-0610-45c3-8e8c-c880eb061121  \n",
      "1402  b49ba6bb-ccd5-4f02-86b9-9e3b37f48fa8  \n",
      "1403  600cc74d-8a0d-458e-b79d-dd77daaa7764  \n",
      "1404  1a6cacf7-6566-46cc-bfaa-10ee29ea1201  \n",
      "\n",
      "[1405 rows x 6 columns]\n",
      "🔒 Connection closed\n"
     ]
    }
   ],
   "source": [
    "import psycopg2\n",
    "import pandas as pd\n",
    "\n",
    "# Connection settings\n",
    "DB_HOST = \"postgres.dev.iris.informa.com\"\n",
    "DB_PORT = \"5432\"\n",
    "DB_NAME = \"aidb\"\n",
    "DB_USER = \"v_svc_usr_aidb\"\n",
    "DB_PASSWORD = \"j<pW@qNsFIc!(OR\"\n",
    "\n",
    "# Create connection\n",
    "try:\n",
    "    conn = psycopg2.connect(\n",
    "        host=DB_HOST,\n",
    "        port=DB_PORT,\n",
    "        dbname=DB_NAME,\n",
    "        user=DB_USER,\n",
    "        password=DB_PASSWORD\n",
    "    )\n",
    "    print(\"✅ Connected to aidb database\")\n",
    "\n",
    "    # Query langchain_pg_collection\n",
    "    query_col = \"select * from ai.langchain_pg_embedding  where collection_id IN (select uuid from ai.langchain_pg_collection where name = 'internal_private_employee_profiles_vectorstore');\"\n",
    "    df_col = pd.read_sql(query_col, conn)\n",
    "    print(\"\\nlangchain_pg_collection sample:\")\n",
    "    print(df_col)\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"❌ Error: {e}\")\n",
    "\n",
    "finally:\n",
    "    if 'conn' in locals():\n",
    "        conn.close()\n",
    "        print(\"🔒 Connection closed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "25375e75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Users\\SinhaK\\AppData\\Local\\miniconda3\\envs\\elysia-dev-env\\python.exe\n",
      "\n",
      "PYTHONPATH:\n",
      "c:\\Users\\SinhaK\\AppData\\Local\\miniconda3\\envs\\elysia-dev-env\\python311.zip\n",
      "c:\\Users\\SinhaK\\AppData\\Local\\miniconda3\\envs\\elysia-dev-env\\DLLs\n",
      "c:\\Users\\SinhaK\\AppData\\Local\\miniconda3\\envs\\elysia-dev-env\\Lib\n",
      "c:\\Users\\SinhaK\\AppData\\Local\\miniconda3\\envs\\elysia-dev-env\n",
      "\n",
      "c:\\Users\\SinhaK\\AppData\\Local\\miniconda3\\envs\\elysia-dev-env\\Lib\\site-packages\n",
      "c:\\Users\\SinhaK\\AppData\\Local\\miniconda3\\envs\\elysia-dev-env\\Lib\\site-packages\\win32\n",
      "c:\\Users\\SinhaK\\AppData\\Local\\miniconda3\\envs\\elysia-dev-env\\Lib\\site-packages\\win32\\lib\n",
      "c:\\Users\\SinhaK\\AppData\\Local\\miniconda3\\envs\\elysia-dev-env\\Lib\\site-packages\\Pythonwin\n",
      "\n",
      "NumPy: 2.3.2  at  c:\\Users\\SinhaK\\AppData\\Local\\miniconda3\\envs\\elysia-dev-env\\Lib\\site-packages\\numpy\\__init__.py\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print(sys.executable)\n",
    "print(\"\\nPYTHONPATH:\")\n",
    "for p in sys.path: \n",
    "    print(p)\n",
    "\n",
    "try:\n",
    "    import numpy as np\n",
    "    print(\"\\nNumPy:\", np.__version__, \" at \", np.__file__)\n",
    "except Exception as e:\n",
    "    print(\"NumPy import failed:\", e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5f994ac4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.26.4 c:\\Users\\SinhaK\\AppData\\Local\\miniconda3\\envs\\elysia-dev-env\\Lib\\site-packages\\numpy\\__init__.py\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "print(np.__version__, np.__file__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b59734e",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'nltk'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mgemini\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdb\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m EmployeeProfileManager, get_db_config, get_connection_string, connection_check\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\MyWorkspace\\lib-usage\\gemini\\db\\__init__.py:9\u001b[39m\n\u001b[32m      7\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mgemini\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdb\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_connection\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m __get_db_config \u001b[38;5;28;01mas\u001b[39;00m get_db_config\n\u001b[32m      8\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mgemini\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdb\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_connection\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m connection_check \n\u001b[32m----> \u001b[39m\u001b[32m9\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mgemini\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdb\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_vector\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m __get_vector_db \u001b[38;5;28;01mas\u001b[39;00m get_vector_db\n\u001b[32m     10\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mgemini\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdb\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_connection\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m __CustomDatabaseConnectionManager \u001b[38;5;28;01mas\u001b[39;00m CustomDatabaseConnectionManager\n\u001b[32m     11\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mgemini\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdb\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_content\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m __cm \u001b[38;5;28;01mas\u001b[39;00m ContentManager\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\MyWorkspace\\lib-usage\\gemini\\db\\_vector.py:8\u001b[39m\n\u001b[32m      6\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpsycopg2\u001b[39;00m\n\u001b[32m      7\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mgemini\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcommon\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m DbType\n\u001b[32m----> \u001b[39m\u001b[32m8\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mgemini\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m get_logger\n\u001b[32m      9\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mlangchain\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01membeddings\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mbase\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Embeddings\n\u001b[32m     10\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mlangchain\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mvectorstores\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mbase\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m VectorStore\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\MyWorkspace\\lib-usage\\gemini\\utils\\__init__.py:16\u001b[39m\n\u001b[32m     14\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mgemini\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_utils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m __extract_domain \u001b[38;5;28;01mas\u001b[39;00m extract_domain\n\u001b[32m     15\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mgemini\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_utils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m __remove_dups \u001b[38;5;28;01mas\u001b[39;00m remove_dups\n\u001b[32m---> \u001b[39m\u001b[32m16\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mgemini\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_nlp\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m __add_preprocessed_text \u001b[38;5;28;01mas\u001b[39;00m add_preprocessed_text\n\u001b[32m     17\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mgemini\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_nlp\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m __create_stopwords \u001b[38;5;28;01mas\u001b[39;00m create_stopwords\n\u001b[32m     18\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mgemini\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_utils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m __generate_uuid \u001b[38;5;28;01mas\u001b[39;00m generate_uuid\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\MyWorkspace\\lib-usage\\gemini\\utils\\_nlp.py:9\u001b[39m\n\u001b[32m      7\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mgensim\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m corpora\n\u001b[32m      8\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mgensim\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmodels\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m LdaModel, CoherenceModel\n\u001b[32m----> \u001b[39m\u001b[32m9\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnltk\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m SnowballStemmer, WordNetLemmatizer\n\u001b[32m     10\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mre\u001b[39;00m\n\u001b[32m     11\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mgensim\u001b[39;00m\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'nltk'"
     ]
    }
   ],
   "source": [
    "import psycopg2\n",
    "\n",
    "# Database connection settings\n",
    "DB_HOST = \"localhost\"        # Change if remote\n",
    "DB_PORT = \"5432\"\n",
    "DB_NAME = \"aidb\"\n",
    "DB_USER = \"your_username\"\n",
    "DB_PASSWORD = \"your_password\"\n",
    "\n",
    "try:\n",
    "    # Connect to PostgreSQL\n",
    "    conn = psycopg2.connect(\n",
    "        host=DB_HOST,\n",
    "        port=DB_PORT,\n",
    "        database=DB_NAME,\n",
    "        user=DB_USER,\n",
    "        password=DB_PASSWORD\n",
    "    )\n",
    "    print(\"✅ Connected to PostgreSQL database!\")\n",
    "\n",
    "    # Create cursor\n",
    "    cur = conn.cursor()\n",
    "\n",
    "    # Query the employee_profile table\n",
    "    cur.execute(\"SELECT * FROM employee_profile LIMIT 10;\")\n",
    "    rows = cur.fetchall()\n",
    "\n",
    "    for row in rows:\n",
    "        print(row)\n",
    "\n",
    "    # Close connection\n",
    "    cur.close()\n",
    "    conn.close()\n",
    "    print(\"✅ Connection closed.\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(\"❌ Error connecting to database:\", e)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "132e213f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "elysia-dev-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
