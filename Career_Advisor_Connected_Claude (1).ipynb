{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dd384fec",
   "metadata": {},
   "source": [
    "\n",
    "# Career Advisor — **Interactive Session** (PGVector + AWS KB, Claude 3.7 Sonnet)\n",
    "\n",
    "This notebook runs a **real session** end‑to‑end with your enterprise data sources.\n",
    "\n",
    "Flow:\n",
    "1. Start with a rotating learning quote + privacy message.\n",
    "2. Ask for **email** (or use “Find me” by name + division) to retrieve your profile from **PGVector**.\n",
    "3. If found, show retrieved skills and let you confirm/update them. If not found, capture skills manually.\n",
    "4. Always query:\n",
    "   - **PGVector collections** (e.g., `internal_private_employee_profiles_vectorstore`, `internal_curated_informa_vectorstore`)\n",
    "   - **AWS Knowledge Bases** (Jobs/Courses) if IDs configured\n",
    "5. Synthesize: brag line, “In 2 minutes I’ll…”, **Closest roles**, **Courses to start this month**.\n",
    "6. CTA: “Would you like to explore other courses or open jobs?”\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e544f5f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# --- Setup & Config ---\n",
    "import os, json, re, random, math\n",
    "from typing import List, Dict, Any, Optional, Literal, Tuple\n",
    "from dataclasses import dataclass, field\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from IPython.display import display, Markdown, clear_output\n",
    "\n",
    "# Widgets UI\n",
    "import ipywidgets as W\n",
    "\n",
    "# %pip install -q psycopg[binary] boto3 python-dotenv\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "Persona = Literal[\"IC\",\"Manager\",\"SeniorLeader\"]\n",
    "Intent = Literal[\"job\",\"courses\",\"development_plan\",\"manager_toolkit\",\"leadership_strategy\",\"profile\"]\n",
    "\n",
    "AWS_REGION = os.getenv(\"AWS_REGION\", \"us-west-2\")\n",
    "AWS_MODEL_ID = \"us.anthropic.claude-3-7-sonnet-20250219-v1:0\"  # fixed per requirement\n",
    "\n",
    "# Optional — ONLY if you want vector mode (query embedding). If blank, hybrid mode is used.\n",
    "EMBEDDING_MODEL = os.getenv(\"BEDROCK_EMBEDDING_MODEL\", \"\")\n",
    "\n",
    "JOB_KB_ID = os.getenv(\"JOB_KB_ID\", \"\")\n",
    "COURSES_KB_ID = os.getenv(\"COURSES_KB_ID\", \"\")\n",
    "\n",
    "PG_DSN = os.getenv(\"PG_DSN\", \"\")  # postgresql://user:pass@host:5432/db\n",
    "\n",
    "PG_COLLECTIONS = [\n",
    "    \"internal_private_employee_profiles_vectorstore\",\n",
    "    \"internal_curated_informa_vectorstore\",\n",
    "]\n",
    "\n",
    "SESSION_ONLY = True\n",
    "\n",
    "print(\"LLM:\", AWS_MODEL_ID)\n",
    "print(\"Embedding model (query only):\", EMBEDDING_MODEL or \"<disabled - using hybrid mode>\")\n",
    "print(\"PG_DSN set:\", bool(PG_DSN))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf7faf34",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# --- AWS Clients (optional) ---\n",
    "import boto3\n",
    "\n",
    "try:\n",
    "    bedrock_rt = boto3.client(\"bedrock-runtime\", region_name=AWS_REGION) if EMBEDDING_MODEL else None\n",
    "except Exception as e:\n",
    "    bedrock_rt = None\n",
    "    print(\"⚠️ Bedrock runtime unavailable (query embeddings disabled):\", e)\n",
    "\n",
    "try:\n",
    "    kb_rt = boto3.client(\"bedrock-agent-runtime\", region_name=AWS_REGION) if (JOB_KB_ID or COURSES_KB_ID) else None\n",
    "except Exception as e:\n",
    "    kb_rt = None\n",
    "    print(\"⚠️ Bedrock KB runtime unavailable:\", e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "503bc8ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# --- Optional query embedding (documents are NEVER re-embedded) ---\n",
    "def embed_query(text: str) -> Optional[List[float]]:\n",
    "    if not EMBEDDING_MODEL or not bedrock_rt:\n",
    "        return None\n",
    "    try:\n",
    "        resp = bedrock_rt.invoke_model(\n",
    "            modelId=EMBEDDING_MODEL,\n",
    "            body=json.dumps({\"inputText\": text}),\n",
    "            contentType=\"application/json\",\n",
    "            accept=\"application/json\",\n",
    "        )\n",
    "        body = json.loads(resp.get(\"body\").read())\n",
    "        vec = body.get(\"embedding\") or (body.get(\"embeddings\") or [{}])[0].get(\"embedding\")\n",
    "        return vec\n",
    "    except Exception as e:\n",
    "        print(\"⚠️ embed_query failed:\", e)\n",
    "        return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb959030",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# --- PGVector connection & SQL ---\n",
    "import psycopg\n",
    "\n",
    "def get_pg_conn():\n",
    "    if not PG_DSN:\n",
    "        raise RuntimeError(\"PG_DSN not set\")\n",
    "    return psycopg.connect(PG_DSN)\n",
    "\n",
    "# Vector mode: use stored embeddings with query vector\n",
    "SIMILARITY_SQL = \"\"\"SELECT e.id,\n",
    "       e.embedding,\n",
    "       e.document,\n",
    "       e.cmetadata,\n",
    "       1 - (e.embedding <=> %(query_vec)s) AS score\n",
    "FROM ai.langchain_pg_embedding e\n",
    "JOIN ai.langchain_pg_collection c ON c.uuid = e.collection_id\n",
    "WHERE c.name = %(collection)s\n",
    "ORDER BY e.embedding <=> %(query_vec)s\n",
    "LIMIT %(k)s;\n",
    "\"\"\"\n",
    "\n",
    "# Hybrid prefilter (no query embeddings)\n",
    "KEYWORD_PREFILTER_SQL = \"\"\"SELECT e.id,\n",
    "       e.embedding,\n",
    "       e.document,\n",
    "       e.cmetadata\n",
    "FROM ai.langchain_pg_embedding e\n",
    "JOIN ai.langchain_pg_collection c ON c.uuid = e.collection_id\n",
    "WHERE c.name = %(collection)s\n",
    "  AND (e.document ILIKE '%%' || %(query)s || '%%'\n",
    "       OR CAST(e.cmetadata AS TEXT) ILIKE '%%' || %(query)s || '%%')\n",
    "LIMIT %(k)s;\n",
    "\"\"\"\n",
    "\n",
    "def _to_meta(meta):\n",
    "    if isinstance(meta, (dict, list)):\n",
    "        return meta\n",
    "    try:\n",
    "        return json.loads(meta)\n",
    "    except Exception:\n",
    "        return {\"raw\": str(meta)}\n",
    "\n",
    "def pg_search_vector_mode(collection: str, query: str, k: int = 8) -> List[Dict[str, Any]]:\n",
    "    qvec = embed_query(query)\n",
    "    if qvec is None:\n",
    "        return []\n",
    "    with get_pg_conn() as conn, conn.cursor() as cur:\n",
    "        cur.execute(SIMILARITY_SQL, {\"collection\": collection, \"query_vec\": qvec, \"k\": k})\n",
    "        rows = cur.fetchall()\n",
    "    hits = []\n",
    "    for _id, emb, doc, meta, score in rows:\n",
    "        hits.append({\"id\": _id, \"embedding\": emb, \"document\": doc, \"metadata\": _to_meta(meta), \"score\": float(score), \"collection\": collection})\n",
    "    return hits\n",
    "\n",
    "def _cosine(a: np.ndarray, b: np.ndarray) -> float:\n",
    "    denom = (np.linalg.norm(a) * np.linalg.norm(b))\n",
    "    if denom == 0: return 0.0\n",
    "    return float(np.dot(a, b) / denom)\n",
    "\n",
    "def pg_search_hybrid_mode(collection: str, query: str, pre_k: int = 20, top_k: int = 8) -> List[Dict[str, Any]]:\n",
    "    with get_pg_conn() as conn, conn.cursor() as cur:\n",
    "        cur.execute(KEYWORD_PREFILTER_SQL, {\"collection\": collection, \"query\": query, \"k\": pre_k})\n",
    "        rows = cur.fetchall()\n",
    "    if not rows:\n",
    "        return []\n",
    "    embs, items = [], []\n",
    "    for _id, emb, doc, meta in rows:\n",
    "        v = np.array(emb, dtype=np.float32)\n",
    "        embs.append(v)\n",
    "        items.append({\"id\": _id, \"embedding\": emb, \"document\": doc, \"metadata\": _to_meta(meta), \"collection\": collection})\n",
    "    centroid = np.mean(embs, axis=0)\n",
    "    for it in items:\n",
    "        it[\"score\"] = _cosine(centroid, np.array(it[\"embedding\"], dtype=np.float32))\n",
    "    items.sort(key=lambda x: x[\"score\"], reverse=True)\n",
    "    return items[:top_k]\n",
    "\n",
    "def pg_multi_search(query: str, collections: List[str], mode: str = \"auto\") -> List[Dict[str, Any]]:\n",
    "    all_hits = []\n",
    "    use_vector = (mode == \"vector\") or (mode == \"auto\" and embed_query(query) is not None)\n",
    "    for coll in collections:\n",
    "        try:\n",
    "            if use_vector:\n",
    "                hits = pg_search_vector_mode(coll, query, k=8)\n",
    "            else:\n",
    "                hits = pg_search_hybrid_mode(coll, query, pre_k=25, top_k=8)\n",
    "            all_hits.extend(hits)\n",
    "        except Exception as e:\n",
    "            print(f\"⚠️ PG search failed for {coll}:\", e)\n",
    "    all_hits.sort(key=lambda x: x.get(\"score\") or 0.0, reverse=True)\n",
    "    return all_hits[: max(6, len(collections)) ]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85e14aca",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# --- AWS Knowledge Bases retrieval (optional) ---\n",
    "def kb_retrieve(kb_id: str, query: str, top_k: int = 5) -> List[Dict[str, Any]]:\n",
    "    if not kb_rt or not kb_id:\n",
    "        return []\n",
    "    try:\n",
    "        resp = kb_rt.retrieve(\n",
    "            knowledgeBaseId=kb_id,\n",
    "            retrievalConfiguration={\"vectorSearchConfiguration\": {\"numberOfResults\": top_k}},\n",
    "            retrievalQuery={\"text\": query},\n",
    "        )\n",
    "        results = []\n",
    "        for item in resp.get(\"retrievalResults\", []):\n",
    "            content = item.get(\"content\", {})\n",
    "            title = content.get(\"title\") or (content.get(\"text\", \"\").split(\"\\n\")[0][:80])\n",
    "            results.append({\n",
    "                \"title\": title,\n",
    "                \"snippet\": content.get(\"snippetText\") or content.get(\"text\", \"\")[:200],\n",
    "                \"score\": item.get(\"score\"),\n",
    "                \"source\": item.get(\"location\", {}).get(\"s3Location\", {}).get(\"uri\"),\n",
    "                \"kb_id\": kb_id,\n",
    "            })\n",
    "        return results\n",
    "    except Exception as e:\n",
    "        print(\"⚠️ KB retrieve failed:\", e)\n",
    "        return []\n",
    "\n",
    "def kb_search_all(query: str) -> Dict[str, List[Dict[str, Any]]]:\n",
    "    out = {}\n",
    "    if JOB_KB_ID:\n",
    "        out[\"jobs\"] = kb_retrieve(JOB_KB_ID, query, top_k=5)\n",
    "    if COURSES_KB_ID:\n",
    "        out[\"courses\"] = kb_retrieve(COURSES_KB_ID, query, top_k=5)\n",
    "    return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c630f0f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# --- Profile retrieval (Option A) ---\n",
    "LOOKUP_BY_EMAIL_OR_ID = \"\"\"SELECT e.document, e.cmetadata\n",
    "FROM ai.langchain_pg_embedding e\n",
    "JOIN ai.langchain_pg_collection c ON c.uuid = e.collection_id\n",
    "WHERE c.name = 'internal_private_employee_profiles_vectorstore'\n",
    "  AND (e.custom_id = %(employee_id)s OR (e.cmetadata->>'email') = %(email)s)\n",
    "LIMIT 50;\n",
    "\"\"\"\n",
    "\n",
    "FIND_ME_FALLBACK = \"\"\"SELECT e.document, e.cmetadata\n",
    "FROM ai.langchain_pg_embedding e\n",
    "JOIN ai.langchain_pg_collection c ON c.uuid = e.collection_id\n",
    "WHERE c.name = 'internal_private_employee_profiles_vectorstore'\n",
    "  AND (e.cmetadata->>'name') ILIKE '%%' || %(name)s || '%%'\n",
    "  AND (%(division)s IS NULL OR (e.cmetadata->>'division') ILIKE '%%' || %(division)s || '%%')\n",
    "LIMIT 10;\n",
    "\"\"\"\n",
    "\n",
    "def profile_lookup(email: Optional[str] = None, employee_id: Optional[str] = None, name: Optional[str] = None, division: Optional[str] = None) -> List[Dict[str, Any]]:\n",
    "    if not PG_DSN:\n",
    "        return []\n",
    "    with get_pg_conn() as conn, conn.cursor() as cur:\n",
    "        if email or employee_id:\n",
    "            cur.execute(LOOKUP_BY_EMAIL_OR_ID, {\"email\": email, \"employee_id\": employee_id})\n",
    "            rows = cur.fetchall()\n",
    "        else:\n",
    "            cur.execute(FIND_ME_FALLBACK, {\"name\": name or \"\", \"division\": division})\n",
    "            rows = cur.fetchall()\n",
    "    out = []\n",
    "    for doc, meta in rows:\n",
    "        if not isinstance(meta, (dict, list)):\n",
    "            try: meta = json.loads(meta)\n",
    "            except: meta = {\"raw\": meta}\n",
    "        out.append({\"document\": doc, \"metadata\": meta})\n",
    "    return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9865f30e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# --- State & Engagement ---\n",
    "@dataclass\n",
    "class Profile:\n",
    "    employee_id: Optional[str] = None\n",
    "    name: Optional[str] = None\n",
    "    title: Optional[str] = None\n",
    "    band: Optional[str] = None\n",
    "    division: Optional[str] = None\n",
    "    skills: List[str] = field(default_factory=list)\n",
    "    interests: List[str] = field(default_factory=list)\n",
    "\n",
    "@dataclass\n",
    "class SessionState:\n",
    "    persona: Persona = \"IC\"\n",
    "    intents: List[Intent] = field(default_factory=list)\n",
    "    profile: Optional[Profile] = None\n",
    "    curated_hits: List[Dict[str, Any]] = field(default_factory=list)\n",
    "    kb_hits: Dict[str, List[Dict[str, Any]]] = field(default_factory=dict)\n",
    "    job_hits: List[Dict[str, Any]] = field(default_factory=list)\n",
    "    course_hits: List[Dict[str, Any]] = field(default_factory=list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "371d60ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "QUOTES = [\n",
    "    (\"We are what we repeatedly do. Excellence, then, is not an act but a habit.\", \"Will Durant\"),\n",
    "    (\"Learning never exhausts the mind.\", \"Leonardo da Vinci\"),\n",
    "    (\"What we know is a drop; what we don’t know is an ocean.\", \"Isaac Newton\"),\n",
    "    (\"Once you stop learning, you start dying.\", \"Albert Einstein\"),\n",
    "    (\"The only limit to our realization of tomorrow is our doubts of today.\", \"F. D. Roosevelt\"),\n",
    "]\n",
    "VALUE_PROMISE = (\n",
    "    \"In 2 minutes, I’ll:\\n\"\n",
    "    \"✅ Recommend 2 career paths in Informa\\n\"\n",
    "    \"✅ Show the 3 most valuable skills to build next\\n\"\n",
    "    \"✅ Give you 2 courses to start this month\\n\\n\"\n",
    "    \"Shall we begin?\"\n",
    ")\n",
    "CAPABILITY_MAP = {\n",
    "    \"data\":\"analytics_modeling\",\"analyst\":\"analytics_modeling\",\"scientist\":\"analytics_modeling\",\n",
    "    \"ml\":\"ml_engineering\",\"backend\":\"systems_backend\",\"platform\":\"systems_backend\",\"sre\":\"reliability_engineering\",\n",
    "    \"frontend\":\"frontend_engineering\",\"product\":\"product_discovery\",\"design\":\"ux_research\",\n",
    "    \"manager\":\"hiring_coaching\",\"lead\":\"people_leadership\",\"director\":\"portfolio_strategy\",\"vp\":\"portfolio_strategy\",\n",
    "    \"ops\":\"process_excellence\",\"support\":\"customer_success\",\"automation\":\"automation\",\"cloud\":\"cloud_platforms\",\n",
    "}\n",
    "PRETTY = {\n",
    "    \"analytics_modeling\":\"analytics & modeling\",\"ml_engineering\":\"ML engineering\",\"systems_backend\":\"backend systems\",\n",
    "    \"reliability_engineering\":\"site reliability\",\"frontend_engineering\":\"frontend engineering\",\"product_discovery\":\"product discovery\",\n",
    "    \"ux_research\":\"UX research\",\"hiring_coaching\":\"hiring & coaching\",\"people_leadership\":\"people leadership\",\n",
    "    \"portfolio_strategy\":\"portfolio strategy\",\"process_excellence\":\"process excellence\",\"customer_success\":\"customer success\",\n",
    "    \"automation\":\"automation\",\"cloud_platforms\":\"cloud platforms\",\n",
    "}\n",
    "\n",
    "def pretty_cap(cap: str) -> str:\n",
    "    return PRETTY.get(cap, cap.replace(\"_\",\" \"))\n",
    "\n",
    "def choose_capability(title: str, skills: List[str], interests: List[str]) -> Optional[str]:\n",
    "    t = (title or \"\").lower()\n",
    "    s = [x.lower() for x in (skills or [])]\n",
    "    i = [x.lower() for x in (interests or [])]\n",
    "    for key, cap in CAPABILITY_MAP.items():\n",
    "        if key in t: return cap\n",
    "    for key, cap in CAPABILITY_MAP.items():\n",
    "        if any(key in x for x in s) or any(key in x for x in i):\n",
    "            return cap\n",
    "    return None\n",
    "\n",
    "def benchmark_line(profile: Profile) -> Optional[str]:\n",
    "    cap = choose_capability(profile.title, profile.skills, profile.interests)\n",
    "    if not cap: return None\n",
    "    hits = sum(1 for s in (profile.skills or []) if any(k in s.lower() for k, c in CAPABILITY_MAP.items() if c == cap))\n",
    "    score = min(1.0, hits * 0.15 + (0.05 if \"learning\" in \" \".join(profile.interests or []).lower() else 0.0))\n",
    "    if score >= 0.67: return f\"You’re stronger in {pretty_cap(cap)} than about 70% of your peer group.\"\n",
    "    if score >= 0.5:  return f\"Your {pretty_cap(cap)} capability is above the median for your peer group.\"\n",
    "    return f\"Your {pretty_cap(cap)} capability is developing; I’ll recommend quick wins.\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b045c35f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def detect_intents(utterance: str) -> List[Intent]:\n",
    "    txt = utterance.lower()\n",
    "    intents = set()\n",
    "    if any(k in txt for k in [\"job\",\"role\",\"opening\",\"posting\"]): intents.add(\"job\")\n",
    "    if any(k in txt for k in [\"course\",\"learn\",\"upskill\",\"training\"]): intents.add(\"courses\")\n",
    "    if any(k in txt for k in [\"plan\",\"30-day\",\"development\"]): intents.add(\"development_plan\")\n",
    "    if any(k in txt for k in [\"manager\",\"team\",\"coach\"]): intents.add(\"manager_toolkit\")\n",
    "    if any(k in txt for k in [\"leadership\",\"strategy\",\"org\"]): intents.add(\"leadership_strategy\")\n",
    "    return sorted(list(intents or {\"profile\"}))\n",
    "\n",
    "def retrieve_everywhere(query: str, mode: str = \"auto\") -> Dict[str, Any]:\n",
    "    pg_hits = pg_multi_search(query, PG_COLLECTIONS, mode=mode) if PG_DSN else []\n",
    "    kb_hits = kb_search_all(query)\n",
    "    return {\"pg\": pg_hits, \"kb\": kb_hits}\n",
    "\n",
    "def suggest_roles_and_courses(profile: Profile, retrieved: Dict[str, Any]) -> Tuple[List[Dict[str, Any]], List[Dict[str, Any]]]:\n",
    "    text_blobs = []\n",
    "    for h in retrieved.get(\"pg\", []):\n",
    "        text_blobs.append((h.get(\"document\") or \"\") + \" \" + json.dumps(h.get(\"metadata\") or {}))\n",
    "    for k, lst in (retrieved.get(\"kb\") or {}).items():\n",
    "        for it in lst:\n",
    "            text_blobs.append((it.get(\"snippet\") or \"\") + \" \" + (it.get(\"title\") or \"\"))\n",
    "    big = \" \".join(text_blobs).lower()\n",
    "\n",
    "    cap = choose_capability(profile.title, profile.skills, profile.interests) or \"analytics_modeling\"\n",
    "    roles = []\n",
    "    if \"frontend\" in big:\n",
    "        roles = [{\"title\":\"Senior Frontend Engineer\",\"match\":0.86},{\"title\":\"UI Engineer\",\"match\":0.81}]\n",
    "    elif \"reliability\" in big or \"slo\" in big:\n",
    "        roles = [{\"title\":\"Site Reliability Engineer\",\"match\":0.88},{\"title\":\"Platform Engineer\",\"match\":0.82}]\n",
    "    elif \"product\" in big or \"roadmap\" in big:\n",
    "        roles = [{\"title\":\"Senior Product Manager\",\"match\":0.84},{\"title\":\"Product Lead\",\"match\":0.80}]\n",
    "    else:\n",
    "        roles = [{\"title\":\"Senior Data Analyst\",\"match\":0.85},{\"title\":\"Analytics Engineer\",\"match\":0.82}]\n",
    "\n",
    "    courses = [{\"title\": it.get(\"title\"), \"source\":\"KB\"} for it in (retrieved.get(\"kb\", {}).get(\"courses\", []) or [])[:2]]\n",
    "    if not courses:\n",
    "        if cap == \"frontend_engineering\":\n",
    "            courses = [{\"title\":\"Modern React\"},{\"title\":\"Testing React Apps\"}]\n",
    "        elif cap == \"systems_backend\":\n",
    "            courses = [{\"title\":\"Designing RESTful APIs\"},{\"title\":\"Observability Essentials\"}]\n",
    "        else:\n",
    "            courses = [{\"title\":\"Advanced SQL Patterns\"},{\"title\":\"Feature Engineering\"}]\n",
    "    return roles, courses\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17380093",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# --- Interactive UI ---\n",
    "quote, author = random.choice(QUOTES)\n",
    "greeting = W.HTML(value=f\"<h3>“{quote}” — {author}</h3><p><em>I don’t store your info — anything you share is used only for this session.</em></p>\")\n",
    "prompt = W.HTML(value=\"<b>To personalize, enter your corporate email (or click 'Find me' to search by name + division).</b>\")\n",
    "\n",
    "email = W.Text(placeholder=\"you@informa.com\", description=\"Email:\", layout=W.Layout(width=\"50%\"))\n",
    "use_find_me = W.Checkbox(value=False, description=\"Find me instead\")\n",
    "name = W.Text(placeholder=\"Your name\", description=\"Name:\")\n",
    "division = W.Text(placeholder=\"Division (optional)\", description=\"Division:\")\n",
    "mode_dd = W.Dropdown(options=[(\"Auto (vector if possible)\", \"auto\"), (\"Vector (requires query embedding)\", \"vector\"), (\"Hybrid (no embeddings)\", \"hybrid\")], value=\"auto\", description=\"Retrieval:\")\n",
    "utterance = W.Text(placeholder=\"e.g., What jobs and courses should I consider next quarter?\", description=\"Question:\", layout=W.Layout(width=\"80%\"))\n",
    "go_btn = W.Button(description=\"Start\", button_style=\"primary\", icon=\"play\")\n",
    "box_identity = W.VBox([greeting, prompt, W.HBox([email, use_find_me]), W.HBox([name, division]), mode_dd, utterance, go_btn])\n",
    "\n",
    "display(box_identity)\n",
    "\n",
    "out = W.Output()\n",
    "display(out)\n",
    "\n",
    "skills_box = W.VBox([])  # will be populated dynamically\n",
    "results_out = W.Output()\n",
    "display(results_out)\n",
    "\n",
    "def on_toggle_find_me(change):\n",
    "    name.disabled = not change[\"new\"]\n",
    "    division.disabled = not change[\"new\"]\n",
    "    email.disabled = change[\"new\"]\n",
    "\n",
    "use_find_me.observe(on_toggle_find_me, names=\"value\")\n",
    "on_toggle_find_me({\"new\": use_find_me.value})\n",
    "\n",
    "def parse_skills(s: str) -> List[str]:\n",
    "    return [x.strip() for x in re.split(r\"[;,\\n]\", s or \"\") if x.strip()]\n",
    "\n",
    "def start_session(_):\n",
    "    results_out.clear_output()\n",
    "    out.clear_output()\n",
    "    skills_box.children = []\n",
    "    with out:\n",
    "        clear_output()\n",
    "        print(\"Looking up profile…\")\n",
    "    # Lookup profile\n",
    "    prof = None\n",
    "    if use_find_me.value:\n",
    "        hits = profile_lookup(name=name.value or None, division=division.value or None)\n",
    "    else:\n",
    "        hits = profile_lookup(email=email.value or None)\n",
    "    if hits:\n",
    "        meta = hits[0][\"metadata\"]\n",
    "        prof = Profile(\n",
    "            name=meta.get(\"name\"),\n",
    "            title=meta.get(\"title\"),\n",
    "            band=meta.get(\"band\"),\n",
    "            division=meta.get(\"division\"),\n",
    "            skills=meta.get(\"skills\", []),\n",
    "            interests=meta.get(\"interests\", []),\n",
    "        )\n",
    "        with out:\n",
    "            clear_output()\n",
    "            print(\"Is this you? If not, adjust below and continue.\")\n",
    "        # Show skills confirmation editor\n",
    "        skill_tags = \", \".join(prof.skills) if prof.skills else \"\"\n",
    "        interests_tags = \", \".join(prof.interests) if prof.interests else \"\"\n",
    "        title_w = W.Text(value=prof.title or \"\", description=\"Title:\")\n",
    "        skills_w = W.Text(value=skill_tags, description=\"Skills:\")\n",
    "        interests_w = W.Text(value=interests_tags, description=\"Interests:\")\n",
    "        confirm_btn = W.Button(description=\"Looks good — continue\", button_style=\"success\")\n",
    "        def confirm_click(_b):\n",
    "            prof.title = title_w.value or prof.title\n",
    "            prof.skills = parse_skills(skills_w.value) or prof.skills\n",
    "            prof.interests = parse_skills(interests_w.value) or prof.interests\n",
    "            run_full(prof)\n",
    "        confirm_btn.on_click(confirm_click)\n",
    "        skills_box.children = [title_w, skills_w, interests_w, confirm_btn]\n",
    "        display(skills_box)\n",
    "    else:\n",
    "        with out:\n",
    "            clear_output()\n",
    "            print(\"Couldn’t find you. Please add a quick profile (session-only).\")\n",
    "        # Quick Profile wizard\n",
    "        title_w = W.Text(placeholder=\"e.g., Senior Data Scientist\", description=\"Title:\")\n",
    "        skills_w = W.Text(placeholder=\"Python, SQL, Modeling, Visualization\", description=\"Skills:\")\n",
    "        interests_w = W.Text(placeholder=\"career path, mentoring\", description=\"Interests:\")\n",
    "        continue_btn = W.Button(description=\"Use this profile — continue\", button_style=\"success\")\n",
    "        def cont_click(_b):\n",
    "            prof_q = Profile(title=title_w.value, skills=parse_skills(skills_w.value), interests=parse_skills(interests_w.value))\n",
    "            run_full(prof_q)\n",
    "        continue_btn.on_click(cont_click)\n",
    "        skills_box.children = [title_w, skills_w, interests_w, continue_btn]\n",
    "        display(skills_box)\n",
    "\n",
    "def run_full(prof: Profile):\n",
    "    results_out.clear_output()\n",
    "    # Synthesize greeting & promise\n",
    "    brag = benchmark_line(prof)\n",
    "    header = f\"**Let’s make this worth your time.**\\n\\n\" + (brag + \"\\n\\n\" if brag else \"\") + VALUE_PROMISE\n",
    "    with results_out:\n",
    "        display(Markdown(header))\n",
    "\n",
    "    # Retrieval fusion (PG + KB)\n",
    "    query = utterance.value or \"career development roles and courses\"\n",
    "    retrieved = retrieve_everywhere(query, mode=mode_dd.value)\n",
    "    pg_hits = retrieved.get(\"pg\", [])\n",
    "    kb_hits = retrieved.get(\"kb\", {})\n",
    "\n",
    "    # Grounding bullets\n",
    "    if pg_hits:\n",
    "        bullets = \"\\n\".join([f\"• **{(h.get('metadata') or {}).get('title', 'Internal doc')}** (PG)\" for h in pg_hits[:3]])\n",
    "        display(Markdown(\"**I’ll ground recommendations in these internal resources:**\\n\" + bullets))\n",
    "    if kb_hits.get(\"jobs\") or kb_hits.get(\"courses\"):\n",
    "        lines = []\n",
    "        for k, lst in kb_hits.items():\n",
    "            for it in lst[:2]:\n",
    "                lines.append(f\"• **{it.get('title','KB doc')}** (KB: {k})\")\n",
    "        if lines:\n",
    "            display(Markdown(\"**Plus these Knowledge Base hits:**\\n\" + \"\\n\".join(lines)))\n",
    "\n",
    "    # Suggestions\n",
    "    roles, courses = suggest_roles_and_courses(prof, retrieved)\n",
    "    if roles:\n",
    "        display(Markdown(\"### Closest roles to explore\"))\n",
    "        display(pd.DataFrame(roles))\n",
    "    if courses:\n",
    "        display(Markdown(\"### Courses to start this month\"))\n",
    "        display(pd.DataFrame(courses))\n",
    "\n",
    "    # CTA\n",
    "    display(Markdown(\"**Would you like to explore other courses or open jobs?**\"))\n",
    "\n",
    "go_btn.on_click(start_session)"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
