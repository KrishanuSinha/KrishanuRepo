{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fbb06b86",
   "metadata": {},
   "source": [
    "\n",
    "# Career Advisor — **Connected** Jupyter Prototype (PGVector + AWS KB)\n",
    "\n",
    "**LLM fixed:** `us.anthropic.claude-3-7-sonnet-20250219-v1:0`\n",
    "\n",
    "This notebook is designed to be engaging *and* grounded in enterprise data sources:\n",
    "- Rotating learning quote + trust-first greeting\n",
    "- Identity Option A (email/ID) and *Find-me* (name + division) via PGVector\n",
    "- **Always** queries multiple PGVector collections for extra context\n",
    "- Pulls from AWS Knowledge Bases (Jobs & Courses) if IDs are provided\n",
    "- Contextual benchmark (not cloud-by-default), persona-aware synthesis\n",
    "- Simple, dopamine-friendly outputs (roles, gaps, courses)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ce6228d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# --- Setup & Config ---\n",
    "import os, json, re, time, math, statistics, random\n",
    "from typing import List, Dict, Any, Optional, Literal, Tuple\n",
    "from dataclasses import dataclass, field\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from IPython.display import display, Markdown\n",
    "\n",
    "# %pip install -q psycopg[binary] boto3 python-dotenv\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "Persona = Literal[\"IC\",\"Manager\",\"SeniorLeader\"]\n",
    "Intent = Literal[\"job\",\"courses\",\"development_plan\",\"manager_toolkit\",\"leadership_strategy\",\"profile\"]\n",
    "\n",
    "AWS_REGION = os.getenv(\"AWS_REGION\", \"us-west-2\")\n",
    "# LLM is fixed as requested:\n",
    "AWS_MODEL_ID = \"us.anthropic.claude-3-7-sonnet-20250219-v1:0\"\n",
    "EMBEDDING_MODEL = os.getenv(\"BEDROCK_EMBEDDING_MODEL\", \"amazon.titan-embed-text-v2:0\")\n",
    "\n",
    "JOB_KB_ID = os.getenv(\"JOB_KB_ID\", \"\")\n",
    "COURSES_KB_ID = os.getenv(\"COURSES_KB_ID\", \"\")\n",
    "\n",
    "PG_DSN = os.getenv(\"PG_DSN\", \"\")\n",
    "\n",
    "# Collections to always search per query\n",
    "PG_COLLECTIONS = [\n",
    "    \"internal_private_employee_profiles_vectorstore\",\n",
    "    \"internal_curated_informa_vectorstore\",\n",
    "    # add more collections here if needed\n",
    "]\n",
    "\n",
    "SESSION_ONLY = True\n",
    "print(\"Configured LLM:\", AWS_MODEL_ID)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29c52ca0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# --- AWS Clients (Bedrock Runtime + Knowledge Bases) ---\n",
    "import boto3\n",
    "\n",
    "try:\n",
    "    bedrock_rt = boto3.client(\"bedrock-runtime\", region_name=AWS_REGION)\n",
    "except Exception as e:\n",
    "    bedrock_rt = None\n",
    "    print(\"⚠️ Bedrock runtime client not available:\", e)\n",
    "\n",
    "try:\n",
    "    kb_rt = boto3.client(\"bedrock-agent-runtime\", region_name=AWS_REGION) if (JOB_KB_ID or COURSES_KB_ID) else None\n",
    "except Exception as e:\n",
    "    kb_rt = None\n",
    "    print(\"⚠️ Bedrock KB client not available:\", e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28be586e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# --- Embedding helper (Titan) ---\n",
    "def embed_text(text: str) -> Optional[List[float]]:\n",
    "    if not bedrock_rt:\n",
    "        return None\n",
    "    try:\n",
    "        resp = bedrock_rt.invoke_model(\n",
    "            modelId=\"amazon.titan-embed-text-v2:0\",\n",
    "            body=json.dumps({\"inputText\": text}),\n",
    "            contentType=\"application/json\",\n",
    "            accept=\"application/json\",\n",
    "        )\n",
    "        body = json.loads(resp.get(\"body\").read())\n",
    "        vec = body.get(\"embedding\") or body.get(\"embeddings\", [{}])[0].get(\"embedding\")\n",
    "        return vec\n",
    "    except Exception as e:\n",
    "        print(\"⚠️ Embedding failed:\", e)\n",
    "        return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a1bd95e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# --- Postgres (PGVector) connection & helpers ---\n",
    "import psycopg\n",
    "\n",
    "def get_pg_conn():\n",
    "    if not PG_DSN:\n",
    "        raise RuntimeError(\"PG_DSN not set in environment.\")\n",
    "    return psycopg.connect(PG_DSN)\n",
    "\n",
    "SIMILARITY_SQL = \"\"\"SELECT e.id,\n",
    "       e.document,\n",
    "       e.cmetadata,\n",
    "       1 - (e.embedding <=> %(query_vec)s) AS score\n",
    "FROM ai.langchain_pg_embedding e\n",
    "JOIN ai.langchain_pg_collection c ON c.uuid = e.collection_id\n",
    "WHERE c.name = %(collection)s\n",
    "ORDER BY e.embedding <=> %(query_vec)s\n",
    "LIMIT %(k)s;\n",
    "\"\"\"\n",
    "\n",
    "KEYWORD_SQL = \"\"\"SELECT e.id,\n",
    "       e.document,\n",
    "       e.cmetadata\n",
    "FROM ai.langchain_pg_embedding e\n",
    "JOIN ai.langchain_pg_collection c ON c.uuid = e.collection_id\n",
    "WHERE c.name = %(collection)s\n",
    "  AND (e.document ILIKE '%%' || %(query)s || '%%'\n",
    "       OR CAST(e.cmetadata AS TEXT) ILIKE '%%' || %(query)s || '%%')\n",
    "LIMIT %(k)s;\n",
    "\"\"\"\n",
    "\n",
    "def pg_similarity_search(collection: str, query: str, k: int = 6) -> List[Dict[str, Any]]:\n",
    "    vec = embed_text(query)\n",
    "    use_embed = vec is not None\n",
    "    with get_pg_conn() as conn, conn.cursor() as cur:\n",
    "        if use_embed:\n",
    "            cur.execute(SIMILARITY_SQL, {\"collection\": collection, \"query_vec\": vec, \"k\": k})\n",
    "            rows = cur.fetchall()\n",
    "        else:\n",
    "            cur.execute(KEYWORD_SQL, {\"collection\": collection, \"query\": query, \"k\": k})\n",
    "            rows = cur.fetchall()\n",
    "\n",
    "    hits = []\n",
    "    for r in rows:\n",
    "        if use_embed:\n",
    "            _id, doc, meta, score = r\n",
    "        else:\n",
    "            _id, doc, meta = r\n",
    "            score = None\n",
    "        if isinstance(meta, str):\n",
    "            try: meta = json.loads(meta)\n",
    "            except: meta = {\"raw\": meta}\n",
    "        hits.append({\"id\": _id, \"document\": doc, \"metadata\": meta, \"score\": score, \"collection\": collection})\n",
    "    return hits\n",
    "\n",
    "def pg_multi_search(query: str, collections: List[str], k_each: int = 4) -> List[Dict[str, Any]]:\n",
    "    all_hits = []\n",
    "    for coll in collections:\n",
    "        try:\n",
    "            all_hits.extend(pg_similarity_search(coll, query, k=k_each))\n",
    "        except Exception as e:\n",
    "            print(f\"⚠️ PG search failed for {coll}:\", e)\n",
    "    def key(h): return (h.get(\"score\") or 0.0)\n",
    "    return sorted(all_hits, key=key, reverse=True)[: max(5, len(collections)) ]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "281bb2bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# --- AWS Knowledge Bases retrieval ---\n",
    "def kb_retrieve(kb_id: str, query: str, top_k: int = 5) -> List[Dict[str, Any]]:\n",
    "    if not kb_rt or not kb_id:\n",
    "        return []\n",
    "    try:\n",
    "        resp = kb_rt.retrieve(\n",
    "            knowledgeBaseId=kb_id,\n",
    "            retrievalConfiguration={\"vectorSearchConfiguration\": {\"numberOfResults\": top_k}},\n",
    "            retrievalQuery={\"text\": query},\n",
    "        )\n",
    "        results = []\n",
    "        for item in resp.get(\"retrievalResults\", []):\n",
    "            content = item.get(\"content\", {})\n",
    "            title = content.get(\"title\") or (content.get(\"text\", \"\").split(\"\\n\")[0][:80])\n",
    "            results.append({\n",
    "                \"title\": title,\n",
    "                \"snippet\": content.get(\"snippetText\") or content.get(\"text\", \"\")[:200],\n",
    "                \"score\": item.get(\"score\"),\n",
    "                \"source\": item.get(\"location\", {}).get(\"s3Location\", {}).get(\"uri\"),\n",
    "                \"kb_id\": kb_id,\n",
    "            })\n",
    "        return results\n",
    "    except Exception as e:\n",
    "        print(\"⚠️ KB retrieve failed:\", e)\n",
    "        return []\n",
    "\n",
    "def kb_search_all(query: str) -> Dict[str, List[Dict[str, Any]]]:\n",
    "    out = {}\n",
    "    if JOB_KB_ID:\n",
    "        out[\"jobs\"] = kb_retrieve(JOB_KB_ID, query, top_k=5)\n",
    "    if COURSES_KB_ID:\n",
    "        out[\"courses\"] = kb_retrieve(COURSES_KB_ID, query, top_k=5)\n",
    "    return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ed5901d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# --- Profile retrieval (Option A) ---\n",
    "LOOKUP_BY_EMAIL_OR_ID = \"\"\"SELECT e.document, e.cmetadata\n",
    "FROM ai.langchain_pg_embedding e\n",
    "JOIN ai.langchain_pg_collection c ON c.uuid = e.collection_id\n",
    "WHERE c.name = 'internal_private_employee_profiles_vectorstore'\n",
    "  AND (e.custom_id = %(employee_id)s OR (e.cmetadata->>'email') = %(email)s)\n",
    "LIMIT 50;\n",
    "\"\"\"\n",
    "\n",
    "FIND_ME_FALLBACK = \"\"\"SELECT e.document, e.cmetadata\n",
    "FROM ai.langchain_pg_embedding e\n",
    "JOIN ai.langchain_pg_collection c ON c.uuid = e.collection_id\n",
    "WHERE c.name = 'internal_private_employee_profiles_vectorstore'\n",
    "  AND (e.cmetadata->>'name') ILIKE '%%' || %(name)s || '%%'\n",
    "  AND (%(division)s IS NULL OR (e.cmetadata->>'division') ILIKE '%%' || %(division)s || '%%')\n",
    "LIMIT 10;\n",
    "\"\"\"\n",
    "\n",
    "def profile_lookup(email: Optional[str] = None, employee_id: Optional[str] = None, name: Optional[str] = None, division: Optional[str] = None) -> List[Dict[str, Any]]:\n",
    "    if not PG_DSN:\n",
    "        return []\n",
    "    with get_pg_conn() as conn, conn.cursor() as cur:\n",
    "        if email or employee_id:\n",
    "            cur.execute(LOOKUP_BY_EMAIL_OR_ID, {\"email\": email, \"employee_id\": employee_id})\n",
    "            rows = cur.fetchall()\n",
    "        else:\n",
    "            cur.execute(FIND_ME_FALLBACK, {\"name\": name or \"\", \"division\": division})\n",
    "            rows = cur.fetchall()\n",
    "    out = []\n",
    "    for doc, meta in rows:\n",
    "        if isinstance(meta, str):\n",
    "            try: meta = json.loads(meta)\n",
    "            except: meta = {\"raw\": meta}\n",
    "        out.append({\"document\": doc, \"metadata\": meta})\n",
    "    return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d565aec",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# --- State & helpers ---\n",
    "@dataclass\n",
    "class Profile:\n",
    "    employee_id: Optional[str] = None\n",
    "    name: Optional[str] = None\n",
    "    title: Optional[str] = None\n",
    "    band: Optional[str] = None\n",
    "    division: Optional[str] = None\n",
    "    skills: List[str] = field(default_factory=list)\n",
    "    interests: List[str] = field(default_factory=list)\n",
    "\n",
    "@dataclass\n",
    "class SessionState:\n",
    "    employee_id: Optional[str] = None\n",
    "    persona: Persona = \"IC\"\n",
    "    intents: List[Intent] = field(default_factory=list)\n",
    "    profile: Optional[Profile] = None\n",
    "    extracted_skills: List[str] = field(default_factory=list)\n",
    "    confirmed_skills: List[str] = field(default_factory=list)\n",
    "    gaps: List[str] = field(default_factory=list)\n",
    "    job_hits: List[Dict[str, Any]] = field(default_factory=list)\n",
    "    course_hits: List[Dict[str, Any]] = field(default_factory=list)\n",
    "    curated_hits: List[Dict[str, Any]] = field(default_factory=list)\n",
    "    kb_hits: Dict[str, List[Dict[str, Any]]] = field(default_factory=dict)\n",
    "    correlation_id: Optional[str] = None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de6ef3ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# --- Engagement + Benchmark ---\n",
    "QUOTES = [\n",
    "    (\"We are what we repeatedly do. Excellence, then, is not an act but a habit.\", \"Will Durant\"),\n",
    "    (\"Learning never exhausts the mind.\", \"Leonardo da Vinci\"),\n",
    "    (\"What we know is a drop; what we don’t know is an ocean.\", \"Isaac Newton\"),\n",
    "    (\"Once you stop learning, you start dying.\", \"Albert Einstein\"),\n",
    "    (\"The only limit to our realization of tomorrow is our doubts of today.\", \"F. D. Roosevelt\"),\n",
    "]\n",
    "VALUE_PROMISE = (\n",
    "    \"In 2 minutes, I’ll:\\n\"\n",
    "    \"✅ Recommend 2 career paths in Informa\\n\"\n",
    "    \"✅ Show the 3 most valuable skills to build next\\n\"\n",
    "    \"✅ Give you 2 courses to start this month\\n\\n\"\n",
    "    \"Shall we begin?\"\n",
    ")\n",
    "\n",
    "CAPABILITY_MAP = {\n",
    "    \"data\": \"analytics_modeling\", \"analyst\": \"analytics_modeling\", \"scientist\": \"analytics_modeling\",\n",
    "    \"ml\": \"ml_engineering\", \"backend\": \"systems_backend\", \"platform\": \"systems_backend\", \"sre\": \"reliability_engineering\",\n",
    "    \"frontend\": \"frontend_engineering\", \"product\": \"product_discovery\", \"design\": \"ux_research\",\n",
    "    \"manager\": \"hiring_coaching\", \"lead\": \"people_leadership\", \"director\": \"portfolio_strategy\", \"vp\": \"portfolio_strategy\",\n",
    "    \"ops\": \"process_excellence\", \"support\": \"customer_success\", \"automation\": \"automation\", \"cloud\": \"cloud_platforms\",\n",
    "}\n",
    "PRETTY = {\n",
    "    \"analytics_modeling\": \"analytics & modeling\", \"ml_engineering\": \"ML engineering\", \"systems_backend\": \"backend systems\",\n",
    "    \"reliability_engineering\": \"site reliability\", \"frontend_engineering\": \"frontend engineering\", \"product_discovery\": \"product discovery\",\n",
    "    \"ux_research\": \"UX research\", \"hiring_coaching\": \"hiring & coaching\", \"people_leadership\": \"people leadership\",\n",
    "    \"portfolio_strategy\": \"portfolio strategy\", \"process_excellence\": \"process excellence\", \"customer_success\": \"customer success\",\n",
    "    \"automation\": \"automation\", \"cloud_platforms\": \"cloud platforms\",\n",
    "}\n",
    "\n",
    "def pretty_cap(cap: str) -> str:\n",
    "    return PRETTY.get(cap, cap.replace(\"_\", \" \"))\n",
    "\n",
    "def choose_capability(state: SessionState) -> Optional[str]:\n",
    "    title = (getattr(state.profile, \"title\", None) or \"\").lower()\n",
    "    interests = set([s.lower() for s in getattr(state.profile, \"interests\", [])])\n",
    "    skills = set([s.lower() for s in getattr(state.profile, \"skills\", [])])\n",
    "    for key, cap in CAPABILITY_MAP.items():\n",
    "        if key in title:\n",
    "            return cap\n",
    "    for key, cap in CAPABILITY_MAP.items():\n",
    "        if any(key in s for s in interests) or any(key in s for s in skills):\n",
    "            return cap\n",
    "    return None\n",
    "\n",
    "def capability_score(profile: Profile, capability: str) -> float:\n",
    "    skills = [s.lower() for s in getattr(profile, \"skills\", [])]\n",
    "    interest_bonus = 0.05 if any(k in (getattr(profile, \"interests\", []) or []) for k in (\"career path\", \"learning\", \"mentoring\")) else 0.0\n",
    "    keys = [k for k, cap in CAPABILITY_MAP.items() if cap == capability]\n",
    "    hits = sum(1 for s in skills if any(k in s for k in keys))\n",
    "    score = min(1.0, (hits * 0.15) + interest_bonus)\n",
    "    return max(0.0, score)\n",
    "\n",
    "def rank_percentile(score: float, peers: List[float]) -> float:\n",
    "    if not peers:\n",
    "        return 0.5\n",
    "    sorted_peers = sorted(peers)\n",
    "    below = sum(1 for p in sorted_peers if p <= score)\n",
    "    return below / max(1, len(sorted_peers))\n",
    "\n",
    "def bucketize(score: float, peers: List[float]) -> str:\n",
    "    if not peers or len(peers) < 10:\n",
    "        return \"above average\" if score >= 0.5 else \"developing\"\n",
    "    q = np.quantile(peers, [0.25, 0.5, 0.75])\n",
    "    if score <= q[0]: return \"bottom quartile\"\n",
    "    if score <= q[1]: return \"below median\"\n",
    "    if score <= q[2]: return \"above median\"\n",
    "    return \"top quartile\"\n",
    "\n",
    "def fetch_peer_scores(persona: Persona, band: Optional[str], division: Optional[str]) -> List[float]:\n",
    "    return [i/100 for i in range(10, 95, 3)]\n",
    "\n",
    "def benchmark_line(state: SessionState) -> Optional[str]:\n",
    "    cap = choose_capability(state)\n",
    "    if not cap or not state.profile:\n",
    "        return None\n",
    "    score = capability_score(state.profile, cap)\n",
    "    peers = fetch_peer_scores(state.persona, state.profile.band, state.profile.division)\n",
    "    if len(peers) < 50:\n",
    "        bucket = bucketize(score, peers)\n",
    "        return f\"Your {pretty_cap(cap)} capability looks {bucket} for your band.\"\n",
    "    pct = round(100 * rank_percentile(score, peers))\n",
    "    if pct >= 67:\n",
    "        return f\"You’re stronger in {pretty_cap(cap)} than about {pct}% of your peer group.\"\n",
    "    if pct >= 50:\n",
    "        return f\"Your {pretty_cap(cap)} capability is above the median for your peer group.\"\n",
    "    return f\"Your {pretty_cap(cap)} capability is developing relative to peers; I’ll recommend quick wins.\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f36fa71",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def detect_intents(utterance: str) -> List[Intent]:\n",
    "    txt = utterance.lower()\n",
    "    intents = set()\n",
    "    if any(k in txt for k in [\"job\", \"role\", \"opening\", \"posting\"]): intents.add(\"job\")\n",
    "    if any(k in txt for k in [\"course\", \"learn\", \"upskill\", \"training\"]): intents.add(\"courses\")\n",
    "    if any(k in txt for k in [\"plan\", \"30-day\", \"development\"]): intents.add(\"development_plan\")\n",
    "    if any(k in txt for k in [\"manager\", \"team\", \"coach\"]): intents.add(\"manager_toolkit\")\n",
    "    if any(k in txt for k in [\"leadership\", \"strategy\", \"org\"]): intents.add(\"leadership_strategy\")\n",
    "    return sorted(list(intents or {\"profile\"}))\n",
    "\n",
    "def greeting_block(name: Optional[str], persona: Persona, brag: Optional[str]) -> str:\n",
    "    quote, author = random.choice(QUOTES)\n",
    "    title = f\"Hi {name}, let’s make this worth your time.\" if name else \"Let’s make this worth your time.\"\n",
    "    lines = [f\"“{quote}” — {author}\", f\"**{title}**\"]\n",
    "    if brag:\n",
    "        lines.append(brag)\n",
    "    lines.append(\"_I don’t store your info — anything you share is used only for this session._\\n\")\n",
    "    lines.append(VALUE_PROMISE)\n",
    "    return \"\\n\\n\".join(lines)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2de042e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def retrieve_everywhere(query: str) -> Dict[str, Any]:\n",
    "    pg_hits = pg_multi_search(query, PG_COLLECTIONS, k_each=4) if PG_DSN else []\n",
    "    kb_hits = kb_search_all(query)\n",
    "    return {\"pg\": pg_hits, \"kb\": kb_hits}\n",
    "\n",
    "def suggest_roles_and_courses(state: SessionState, retrieved: Dict[str, Any]) -> Tuple[List[Dict[str, Any]], List[Dict[str, Any]]]:\n",
    "    text_blobs = []\n",
    "    for h in retrieved.get(\"pg\", []):\n",
    "        text_blobs.append((h.get(\"document\") or \"\") + \" \" + json.dumps(h.get(\"metadata\") or {}))\n",
    "    for k, lst in (retrieved.get(\"kb\") or {}).items():\n",
    "        for it in lst:\n",
    "            text_blobs.append((it.get(\"snippet\") or \"\") + \" \" + (it.get(\"title\") or \"\"))\n",
    "    big = \" \".join(text_blobs).lower()\n",
    "\n",
    "    roles = []\n",
    "    if \"frontend\" in big:\n",
    "        roles = [{\"title\": \"Senior Frontend Engineer\", \"match\": 0.86}, {\"title\": \"UI Engineer\", \"match\": 0.81}]\n",
    "    elif \"reliability\" in big or \"slo\" in big:\n",
    "        roles = [{\"title\": \"Site Reliability Engineer\", \"match\": 0.88}, {\"title\": \"Platform Engineer\", \"match\": 0.82}]\n",
    "    elif \"product\" in big or \"roadmap\" in big:\n",
    "        roles = [{\"title\": \"Senior Product Manager\", \"match\": 0.84}, {\"title\": \"Product Lead\", \"match\": 0.80}]\n",
    "    else:\n",
    "        roles = [{\"title\": \"Senior Data Analyst\", \"match\": 0.85}, {\"title\": \"Analytics Engineer\", \"match\": 0.82}]\n",
    "\n",
    "    courses = []\n",
    "    for it in (retrieved.get(\"kb\", {}).get(\"courses\", []) or [])[:2]:\n",
    "        courses.append({\"title\": it.get(\"title\"), \"source\": \"KB\", \"reason\": \"Matched your gaps/context\"})\n",
    "    if not courses:\n",
    "        courses = [{\"title\": \"Learning How to Learn\", \"source\": \"L&D\"}, {\"title\": \"Outcome-Driven Roadmaps\", \"source\": \"L&D\"}]\n",
    "    return roles, courses\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8264f75",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def run_session(\n",
    "    utterance: str,\n",
    "    persona: Persona = \"IC\",\n",
    "    email: Optional[str] = None,\n",
    "    employee_id: Optional[str] = None,\n",
    "    name: Optional[str] = None,\n",
    "    division: Optional[str] = None,\n",
    "    quick_profile: Optional[Dict[str, Any]] = None,\n",
    ") -> SessionState:\n",
    "    state = SessionState(persona=persona)\n",
    "    if quick_profile:\n",
    "        state.profile = Profile(**quick_profile)\n",
    "    else:\n",
    "        results = profile_lookup(email=email, employee_id=employee_id, name=name, division=division)\n",
    "        if results:\n",
    "            meta = results[0][\"metadata\"]\n",
    "            state.profile = Profile(\n",
    "                employee_id=meta.get(\"employee_id\"),\n",
    "                name=meta.get(\"name\"),\n",
    "                title=meta.get(\"title\"),\n",
    "                band=meta.get(\"band\"),\n",
    "                division=meta.get(\"division\"),\n",
    "                skills=meta.get(\"skills\", []),\n",
    "                interests=meta.get(\"interests\", []),\n",
    "            )\n",
    "        else:\n",
    "            state.profile = Profile(skills=[], interests=[])\n",
    "\n",
    "    state.intents = detect_intents(utterance)\n",
    "    retrieved = retrieve_everywhere(utterance)\n",
    "    state.curated_hits = retrieved.get(\"pg\", [])\n",
    "    state.kb_hits = retrieved.get(\"kb\", {})\n",
    "\n",
    "    brag = benchmark_line(state)\n",
    "    display(Markdown(greeting_block(state.profile.name, state.persona, brag)))\n",
    "\n",
    "    roles, courses = suggest_roles_and_courses(state, retrieved)\n",
    "    state.job_hits = roles\n",
    "    state.course_hits = courses\n",
    "\n",
    "    if state.curated_hits:\n",
    "        top2 = state.curated_hits[:2]\n",
    "        bullets = \"\\n\".join([f\"• **{(h.get('metadata') or {}).get('title', 'Internal doc')}** (PG)\" for h in top2])\n",
    "        display(Markdown(\"**I’ll ground recommendations in these internal resources:**\\n\" + bullets))\n",
    "\n",
    "    if state.kb_hits.get(\"jobs\") or state.kb_hits.get(\"courses\"):\n",
    "        lines = []\n",
    "        for k, lst in state.kb_hits.items():\n",
    "            for it in lst[:2]:\n",
    "                lines.append(f\"• **{it.get('title','KB doc')}** (KB: {k})\")\n",
    "        if lines:\n",
    "            display(Markdown(\"**Plus these Knowledge Base hits:**\\n\" + \"\\n\".join(lines)))\n",
    "\n",
    "    if roles:\n",
    "        display(Markdown(\"### Closest roles to explore\"))\n",
    "        display(pd.DataFrame(roles))\n",
    "    if courses:\n",
    "        display(Markdown(\"### Courses to start this month\"))\n",
    "        display(pd.DataFrame(courses))\n",
    "\n",
    "    return state\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4342e58",
   "metadata": {},
   "source": [
    "## Demo — Quick Profile (no identity persisted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c134e65f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "state = run_session(\n",
    "    utterance=\"What job postings or courses fit me next quarter?\",\n",
    "    persona=\"IC\",\n",
    "    quick_profile={\"name\": \"Alex\", \"title\": \"Senior Data Scientist\", \"band\": \"Band 5\", \"division\": \"Analytics\",\n",
    "                   \"skills\": [\"Python\",\"Machine Learning\",\"Visualization\"], \"interests\": [\"career path\",\"forecasting\"]}\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a16a9b2",
   "metadata": {},
   "source": [
    "## Demo — Find-me (name + division) via PGVector profiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88d4ca84",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Requires PG_DSN configured and your profiles collection populated.\n",
    "state = run_session(\n",
    "    utterance=\"Show roles and a 30-day plan.\",\n",
    "    persona=\"Manager\",\n",
    "    name=\"Jordan\",\n",
    "    division=\"Platform\"\n",
    ")\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
