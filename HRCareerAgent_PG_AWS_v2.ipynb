{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9a82de85",
   "metadata": {},
   "source": [
    "\n",
    "# HR Career Advisor — PG Vector + AWS KB (Prototype v2)\n",
    "\n",
    "**What’s new in v2**\n",
    "- Placeholder **user name/email** for quick testing (no AWT needed).\n",
    "- If profile isn’t found, the agent **still answers** with best-effort results.\n",
    "- For common question: *“What jobs and courses should I look at for data engineering?”*,\n",
    "  we include **fallback roles/courses** if retrieval returns empty.\n",
    "- After answering, the agent **asks for profile details** (email or name+division).\n",
    "- If not found, we offer a **30‑sec Quick Profile** (role, skills, interests).\n",
    "\n",
    "Run order:\n",
    "1) Configure env (or use defaults in this notebook).  \n",
    "2) Execute smoke tests at bottom or call `run_workflow(...)` interactively.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3884e5da",
   "metadata": {},
   "source": [
    "## 0) Setup & Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8c8cdff",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os, json, time\n",
    "from typing import List, Dict, Any, Optional, Tuple\n",
    "from dataclasses import dataclass\n",
    "import numpy as np\n",
    "from IPython.display import display, Markdown\n",
    "\n",
    "# %pip install -q psycopg[binary] boto3 python-dotenv\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "AWS_REGION = os.getenv(\"AWS_REGION\", \"us-west-2\")\n",
    "AWS_MODEL_ID = \"us.anthropic.claude-3-7-sonnet-20250219-v1:0\"  # per requirement\n",
    "\n",
    "# --- PG & KBs ---\n",
    "PG_DSN = os.getenv(\"PG_DSN\",\"\")  # postgresql://user:pass@host:5432/dbname (URL-encode password)\n",
    "PG_COLLECTIONS = [\n",
    "    \"internal_private_employee_profiles_vectorstore\",\n",
    "    \"internal_curated_informa_vectorstore\",\n",
    "]\n",
    "JOB_KB_ID = os.getenv(\"JOB_KB_ID\",\"\")\n",
    "COURSES_KB_ID = os.getenv(\"COURSES_KB_ID\",\"\")\n",
    "\n",
    "# --- Prototype placeholders (safe defaults; override via env) ---\n",
    "DEFAULT_USER_NAME  = os.getenv(\"DEFAULT_USER_NAME\",  \"Kedar Santosh Prabhu\")\n",
    "DEFAULT_USER_EMAIL = os.getenv(\"DEFAULT_USER_EMAIL\", \"kedarsantosh.prabhu@informa.com\")\n",
    "DEFAULT_USER_DIV   = os.getenv(\"DEFAULT_USER_DIVISION\", \"\")\n",
    "\n",
    "print(\"Env present:\", dict(\n",
    "    PG=bool(PG_DSN),\n",
    "    JOB_KB=bool(JOB_KB_ID),\n",
    "    COURSES_KB=bool(COURSES_KB_ID),\n",
    "    DEFAULT_USER_NAME=DEFAULT_USER_NAME,\n",
    "    DEFAULT_USER_EMAIL=DEFAULT_USER_EMAIL\n",
    "))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2af3eaf",
   "metadata": {},
   "source": [
    "## 1) PGVector Retrieval (uses stored `embedding` + `document`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d971e82",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import psycopg\n",
    "\n",
    "def get_pg_conn():\n",
    "    if not PG_DSN:\n",
    "        raise RuntimeError(\"PG_DSN not set\")\n",
    "    return psycopg.connect(PG_DSN)\n",
    "\n",
    "# NOTE: e.id does not exist in your schema — use e.uuid AS id\n",
    "KEYWORD_PREFILTER_SQL = \"\"\"SELECT e.uuid AS id, e.embedding, e.document, e.cmetadata, c.name as collection\n",
    "FROM ai.langchain_pg_embedding e\n",
    "JOIN ai.langchain_pg_collection c ON c.uuid = e.collection_id\n",
    "WHERE c.name = %(collection)s\n",
    "  AND (e.document ILIKE '%%' || %(query)s || '%%'\n",
    "       OR CAST(e.cmetadata AS TEXT) ILIKE '%%' || %(query)s || '%%')\n",
    "LIMIT %(k)s;\n",
    "\"\"\"\n",
    "\n",
    "def _to_meta(meta):\n",
    "    if isinstance(meta,(dict,list)): return meta\n",
    "    try: return json.loads(meta)\n",
    "    except: return {\"raw\": str(meta)}\n",
    "\n",
    "def _cosine(a: np.ndarray, b: np.ndarray) -> float:\n",
    "    denom = (np.linalg.norm(a) * np.linalg.norm(b))\n",
    "    if denom == 0: return 0.0\n",
    "    return float(np.dot(a, b) / denom)\n",
    "\n",
    "def pg_search_hybrid(collection: str, query: str, pre_k: int = 24, top_k: int = 8) -> List[Dict[str,Any]]:\n",
    "    with get_pg_conn() as conn, conn.cursor() as cur:\n",
    "        cur.execute(KEYWORD_PREFILTER_SQL, {\"collection\": collection, \"query\": query, \"k\": pre_k})\n",
    "        rows = cur.fetchall()\n",
    "    if not rows: return []\n",
    "    embs, items = [], []\n",
    "    for _id, emb, doc, meta, coll in rows:\n",
    "        v = np.array(emb, dtype=np.float32)\n",
    "        embs.append(v)\n",
    "        items.append({\"id\": _id, \"embedding\": emb, \"document\": doc, \"metadata\": _to_meta(meta), \"collection\": coll})\n",
    "    centroid = np.mean(embs, axis=0)\n",
    "    for it in items:\n",
    "        it[\"score\"] = _cosine(centroid, np.array(it[\"embedding\"], dtype=np.float32))\n",
    "    items.sort(key=lambda x: x.get(\"score\",0.0), reverse=True)\n",
    "    return items[:top_k]\n",
    "\n",
    "def pg_multi_search(query: str, collections: List[str]) -> List[Dict[str,Any]]:\n",
    "    hits = []\n",
    "    for coll in collections:\n",
    "        try:\n",
    "            hits.extend(pg_search_hybrid(coll, query, 24, 8))\n",
    "        except Exception as e:\n",
    "            print(f\"⚠️ PG search failed for {coll}: {e}\")\n",
    "    hits.sort(key=lambda x: x.get(\"score\",0.0), reverse=True)\n",
    "    return hits[: max(6, len(collections)) ]\n",
    "\n",
    "# Profile lookup: prefer name+division if available; email as tiebreaker\n",
    "def profile_lookup(email: Optional[str] = None,\n",
    "                   name: Optional[str] = None,\n",
    "                   division: Optional[str] = None) -> List[Dict[str,Any]]:\n",
    "    if not PG_DSN:\n",
    "        return []\n",
    "    results: List[Dict[str,Any]] = []\n",
    "    with get_pg_conn() as conn, conn.cursor() as cur:\n",
    "        if name:\n",
    "            q_name = \"\"\"            SELECT e.document, e.cmetadata\n",
    "            FROM ai.langchain_pg_embedding e\n",
    "            JOIN ai.langchain_pg_collection c ON c.uuid = e.collection_id\n",
    "            WHERE c.name = 'internal_private_employee_profiles_vectorstore'\n",
    "              AND (e.cmetadata->>'name') ILIKE %(name)s\n",
    "              AND (%(division)s IS NULL OR (e.cmetadata->>'division') ILIKE %(division)s)\n",
    "            LIMIT 25;\n",
    "            \"\"\"\n",
    "            cur.execute(q_name, {\"name\": f\"%{name}%\", \"division\": None if not division else f\"%{division}%\"})\n",
    "            rows = cur.fetchall()\n",
    "            for doc, meta in rows:\n",
    "                try: meta = meta if isinstance(meta, dict) else json.loads(meta)\n",
    "                except: meta = {\"raw\": str(meta)}\n",
    "                results.append({\"document\": doc, \"metadata\": meta})\n",
    "            if email:\n",
    "                exact = [r for r in results if (r[\"metadata\"] or {}).get(\"email\") == email]\n",
    "                if exact:\n",
    "                    return exact\n",
    "            return results\n",
    "        elif email:\n",
    "            q_email = \"\"\"            SELECT e.document, e.cmetadata\n",
    "            FROM ai.langchain_pg_embedding e\n",
    "            JOIN ai.langchain_pg_collection c ON c.uuid = e.collection_id\n",
    "            WHERE c.name = 'internal_private_employee_profiles_vectorstore'\n",
    "              AND (e.cmetadata->>'email') = %(email)s\n",
    "            LIMIT 10;\n",
    "            \"\"\"\n",
    "            cur.execute(q_email, {\"email\": email})\n",
    "            rows = cur.fetchall()\n",
    "            for doc, meta in rows:\n",
    "                try: meta = meta if isinstance(meta, dict) else json.loads(meta)\n",
    "                except: meta = {\"raw\": str(meta)}\n",
    "                results.append({\"document\": doc, \"metadata\": meta})\n",
    "            return results\n",
    "        else:\n",
    "            return []\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7ce6551",
   "metadata": {},
   "source": [
    "## 2) AWS Knowledge Bases Retrieval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e966a60",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import boto3\n",
    "try:\n",
    "    kb_rt = boto3.client(\"bedrock-agent-runtime\", region_name=AWS_REGION) if (JOB_KB_ID or COURSES_KB_ID) else None\n",
    "except Exception as e:\n",
    "    kb_rt = None\n",
    "    print(\"⚠️ AWS KB unavailable:\", e)\n",
    "\n",
    "def kb_retrieve(kb_id: str, query: str, top_k: int = 5) -> List[Dict[str,Any]]:\n",
    "    if not kb_rt or not kb_id:\n",
    "        return []\n",
    "    try:\n",
    "        resp = kb_rt.retrieve(\n",
    "            knowledgeBaseId=kb_id,\n",
    "            retrievalConfiguration={\"vectorSearchConfiguration\": {\"numberOfResults\": top_k}},\n",
    "            retrievalQuery={\"text\": query},\n",
    "        )\n",
    "        out = []\n",
    "        for r in resp.get(\"retrievalResults\", []):\n",
    "            c = r.get(\"content\", {})\n",
    "            out.append({\n",
    "                \"title\": c.get(\"title\") or (c.get(\"text\",\"\").split(\"\\n\")[0][:80]).strip(),\n",
    "                \"snippet\": c.get(\"snippetText\") or c.get(\"text\",\"\")[:240],\n",
    "                \"score\": r.get(\"score\"),\n",
    "                \"kb_id\": kb_id,\n",
    "                \"metadata\": r.get(\"metadata\") or {},\n",
    "                \"source\": r.get(\"location\", {}).get(\"s3Location\", {}).get(\"uri\"),\n",
    "                \"type\": r.get(\"metadata\",{}).get(\"type\")\n",
    "            })\n",
    "        return out\n",
    "    except Exception as e:\n",
    "        print(\"⚠️ KB retrieve failed:\", e)\n",
    "        return []\n",
    "\n",
    "def kb_search_all(query: str) -> Dict[str, List[Dict[str,Any]]]:\n",
    "    return {\n",
    "        \"jobs\":    kb_retrieve(JOB_KB_ID, query, 6) if JOB_KB_ID else [],\n",
    "        \"courses\": kb_retrieve(COURSES_KB_ID, query, 6) if COURSES_KB_ID else [],\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c22678e4",
   "metadata": {},
   "source": [
    "## 3) Prohibitor, State, Intent, Onboarding Helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edba8d15",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "AllowedIntents = {\"courses\",\"job\",\"development_plan\",\"manager_toolkit\",\"leadership_strategy\",\"career\"}\n",
    "\n",
    "def prohibitor(user_text: str) -> Dict[str,Any]:\n",
    "    t = user_text.lower()\n",
    "    allowed = any(k in t for k in [\"career\",\"course\",\"job\",\"role\",\"roles\",\"learn\",\"upskill\",\"development\",\"manager\",\"leadership\",\"okr\",\"coaching\",\"promotion\",\"ladder\",\"mentoring\",\"objective\",\"okrs\"])\n",
    "    intents = []\n",
    "    if any(k in t for k in [\"job\",\"jobs\",\"opening\",\"openings\",\"role\",\"roles\"]): intents.append(\"job\")\n",
    "    if any(k in t for k in [\"course\",\"courses\",\"learn\",\"training\",\"upskill\"]): intents.append(\"courses\")\n",
    "    if any(k in t for k in [\"mentoring\",\"mentor\"]): intents.append(\"manager_toolkit\")\n",
    "    if any(k in t for k in [\"objective\",\"okr\",\"okrs\"]): intents.append(\"leadership_strategy\")\n",
    "    if any(k in t for k in [\"development plan\",\"30-day\",\"60-day\",\"90-day\",\"dev plan\"]): intents.append(\"development_plan\")\n",
    "    if not intents and allowed: intents.append(\"career\")\n",
    "    return {\"allowed\": allowed and bool(intents), \"intents\": intents or [], \"rationale\": \"heuristic v0.2\"}\n",
    "\n",
    "@dataclass\n",
    "class AgentState:\n",
    "    email: Optional[str] = None\n",
    "    name: Optional[str] = None\n",
    "    division: Optional[str] = None\n",
    "    employee_id: Optional[str] = None\n",
    "    is_manager: bool = False\n",
    "    prompt: Optional[str] = None\n",
    "    quick_profile: Optional[Dict[str,Any]] = None\n",
    "\n",
    "def derive_is_manager_from_profile(meta: dict) -> bool:\n",
    "    if str(meta.get(\"is_manager\",\"\")).lower() in {\"true\",\"1\",\"yes\"}: return True\n",
    "    if int(meta.get(\"direct_reports\",0) or 0) > 0: return True\n",
    "    title = (meta.get(\"title\") or \"\").lower()\n",
    "    if any(k in title for k in [\" manager\",\"lead\",\"head of\",\"director\",\"vp\"]): return True\n",
    "    return False\n",
    "\n",
    "def setup_state(email: Optional[str], name: Optional[str], division: Optional[str],\n",
    "                override_is_manager: Optional[bool], user_text: str) -> Tuple[AgentState, dict]:\n",
    "    rows = profile_lookup(email=email or DEFAULT_USER_EMAIL,\n",
    "                          name=name or DEFAULT_USER_NAME,\n",
    "                          division=division or DEFAULT_USER_DIV)\n",
    "    meta = rows[0][\"metadata\"] if rows else {}\n",
    "    is_mgr = override_is_manager if override_is_manager is not None else derive_is_manager_from_profile(meta)\n",
    "    st = AgentState(email=email or DEFAULT_USER_EMAIL, name=name or DEFAULT_USER_NAME,\n",
    "                    division=division or DEFAULT_USER_DIV, employee_id=meta.get(\"employee_id\"),\n",
    "                    is_manager=is_mgr, prompt=user_text)\n",
    "    return st, meta\n",
    "\n",
    "def intent_persona(intents: List[str]) -> List[str]:\n",
    "    return sorted(set(i for i in intents if i in AllowedIntents))\n",
    "\n",
    "def onboarding_message() -> str:\n",
    "    return (\n",
    "        \"**To tailor this to you**, please enter your corporate **email** or **name + division**.\\n\\n\"\n",
    "        \"If we can’t find you, I’ll run a 30‑sec Quick Profile wizard (role, top 5 skills, interests).\"\n",
    "    )\n",
    "\n",
    "def quick_profile_wizard_stub() -> Dict[str,Any]:\n",
    "    return {\n",
    "        \"role\": \"Software Engineer\",\n",
    "        \"skills\": [\"Python\",\"SQL\",\"AWS\",\"Airflow\",\"Data Modeling\"],\n",
    "        \"interests\": [\"Data Engineering\",\"Platform\",\"Analytics\"]\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "912c851f",
   "metadata": {},
   "source": [
    "## 4) Tools (jobs & courses) + Fallbacks + Reflexion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49d149a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def tool_pg_search(query: str, k: int = 8) -> List[Dict[str,Any]]:\n",
    "    return pg_multi_search(query, PG_COLLECTIONS)[:k]\n",
    "\n",
    "def tool_kb_search(query: str, top_k: int = 6) -> Dict[str, List[Dict[str,Any]]]:\n",
    "    return kb_search_all(query)\n",
    "\n",
    "MANAGER_KEYWORDS = {\"manager\",\"leadership\",\"org design\",\"hiring\",\"coaching\",\"performance review\",\"okr\",\"okrs\",\"succession\"}\n",
    "\n",
    "def looks_manager_only(item: Dict[str,Any]) -> bool:\n",
    "    meta = (item.get(\"metadata\") or {})\n",
    "    audience = str(meta.get(\"audience\",\"\")).lower()\n",
    "    title = (item.get(\"title\") or item.get(\"document\") or \"\").lower()\n",
    "    tags = \" \".join(meta.get(\"tags\", [])).lower()\n",
    "    if audience in {\"manager\",\"leadership\"}: return True\n",
    "    haystack = f\"{title} {tags}\"\n",
    "    return any(kw in haystack for kw in MANAGER_KEYWORDS)\n",
    "\n",
    "def explicit_manager_request(prompt: str) -> bool:\n",
    "    p = (prompt or \"\").lower()\n",
    "    return any(k in p for k in MANAGER_KEYWORDS)\n",
    "\n",
    "FALLBACKS = {\n",
    "    \"data engineering\": {\n",
    "        \"jobs\": [\n",
    "            {\"title\": \"Data Engineer (Platform)\"},\n",
    "            {\"title\": \"Analytics Engineer\"},\n",
    "        ],\n",
    "        \"courses\": [\n",
    "            {\"title\": \"Data Engineering on AWS — Foundations\"},\n",
    "            {\"title\": \"Modern Data Pipelines with Python & Airflow\"},\n",
    "        ]\n",
    "    }\n",
    "}\n",
    "\n",
    "def infer_topic(user_text: str) -> Optional[str]:\n",
    "    t = user_text.lower()\n",
    "    if \"data engineering\" in t or \"data engineer\" in t:\n",
    "        return \"data engineering\"\n",
    "    return None\n",
    "\n",
    "def job_tool(query: str) -> List[Dict[str,Any]]:\n",
    "    jobs = []\n",
    "    kb = tool_kb_search(query).get(\"jobs\", [])\n",
    "    pg = [h for h in tool_pg_search(query, 12) if (h.get(\"metadata\") or {}).get(\"type\") in {\"job\",\"role\"}]\n",
    "    jobs.extend(kb[:6] or []); jobs.extend(pg[:6] or [])\n",
    "    seen, dedup = set(), []\n",
    "    for j in jobs:\n",
    "        t = (j.get(\"title\") or (j.get(\"metadata\") or {}).get(\"title\") or \"\").strip().lower()\n",
    "        if not t or t in seen: continue\n",
    "        seen.add(t); dedup.append(j)\n",
    "    if not dedup:\n",
    "        topic = infer_topic(query)\n",
    "        if topic and FALLBACKS.get(topic, {}).get(\"jobs\"):\n",
    "            dedup = FALLBACKS[topic][\"jobs\"]\n",
    "    return dedup[:4]\n",
    "\n",
    "def courses_tool(query: str, state: 'AgentState') -> List[Dict[str,Any]]:\n",
    "    courses = []\n",
    "    kb = tool_kb_search(query).get(\"courses\", [])\n",
    "    pg = [h for h in tool_pg_search(query, 12) if (h.get(\"metadata\") or {}).get(\"type\") == \"course\"]\n",
    "    courses.extend(kb[:8] or []); courses.extend(pg[:6] or [])\n",
    "    if state.is_manager or explicit_manager_request(state.prompt or \"\"):\n",
    "        filtered = courses\n",
    "    else:\n",
    "        filtered = [c for c in courses if not looks_manager_only(c)]\n",
    "    out, seen = [], set()\n",
    "    for c in filtered:\n",
    "        title = c.get(\"title\") or (c.get(\"metadata\") or {}).get(\"title\") or \"Course\"\n",
    "        if title.lower() in seen: continue\n",
    "        seen.add(title.lower())\n",
    "        out.append({\"title\": title, \"metadata\": c.get(\"metadata\") or {}, \"source\": c.get(\"source\") or \"KB/PG\"})\n",
    "    if not out:\n",
    "        topic = infer_topic(query)\n",
    "        if topic and FALLBACKS.get(topic, {}).get(\"courses\"):\n",
    "            out = FALLBACKS[topic][\"courses\"]\n",
    "    return out[:4]\n",
    "\n",
    "def job_reflexion(items: List[Dict[str,Any]]) -> List[Dict[str,Any]]:\n",
    "    return sorted(items, key=lambda x: (-float(x.get(\"score\") or 0.0), len(x.get(\"title\",\"\"))))\n",
    "\n",
    "def courses_reflexion(items: List[Dict[str,Any]], is_manager: bool) -> List[Dict[str,Any]]:\n",
    "    def rank(it):\n",
    "        meta = it.get(\"metadata\") or {}\n",
    "        aud = (meta.get(\"audience\") or \"\").lower()\n",
    "        penal = 0 if is_manager else (1 if aud in {\"manager\",\"leadership\"} else 0)\n",
    "        return (penal, -float(it.get(\"score\") or 0.0))\n",
    "    return sorted(items, key=rank)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2db35dff",
   "metadata": {},
   "source": [
    "## 5) Consolidation & Compose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4604f915",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def dopamine_block() -> str:\n",
    "    return (\n",
    "        \"**Let’s make this worth your time.**\\n\"\n",
    "        \"_I don’t store your info — anything you share is used only for this session._\\n\\n\"\n",
    "        \"In 2 minutes, I’ll:\\n\"\n",
    "        \"✅ Recommend 2 career paths in Informa\\n\"\n",
    "        \"✅ Show the 3 most valuable skills to build next\\n\"\n",
    "        \"✅ Give you 2 courses to start this month\\n\"\n",
    "    )\n",
    "\n",
    "def consolidation_summary(sections: Dict[str,Any], include_onboarding: bool = True) -> str:\n",
    "    blocks = [dopamine_block()]\n",
    "    jobs = sections.get(\"jobs\") or []\n",
    "    courses = sections.get(\"courses\") or []\n",
    "    if jobs:\n",
    "        blocks.append(\"\\n### Closest roles to explore\")\n",
    "        for j in jobs[:2]:\n",
    "            t = j.get(\"title\") or (j.get(\"metadata\") or {}).get(\"title\") or \"Role\"\n",
    "            blocks.append(f\"- {t}\")\n",
    "    if courses:\n",
    "        blocks.append(\"\\n### Courses to start this month\")\n",
    "        for c in courses[:2]:\n",
    "            blocks.append(f\"- {c.get('title','Course')}\")\n",
    "    if include_onboarding:\n",
    "        blocks.append(\"\\n\" + onboarding_message())\n",
    "    blocks.append(\"\\n**Would you like to explore other courses or open jobs?**\")\n",
    "    return \"\\n\".join(blocks)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2c19de3",
   "metadata": {},
   "source": [
    "## 6) Orchestrator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6a1fcc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def run_workflow(user_text: str,\n",
    "                 email: Optional[str] = None,\n",
    "                 name: Optional[str] = None,\n",
    "                 division: Optional[str] = None,\n",
    "                 override_is_manager: Optional[bool] = None) -> Dict[str,Any]:\n",
    "    gate = prohibitor(user_text)\n",
    "    if not gate.get(\"allowed\"):\n",
    "        answer = \"I’m scoped to career planning (roles/jobs, courses, development plans, manager/leadership toolkits, leadership strategy). Ask me one of those and I’ll help fast.\"\n",
    "        return {\"blocked\": True, \"gate\": gate, \"answer\": answer}\n",
    "\n",
    "    state, profile_meta = setup_state(email=email, name=name, division=division,\n",
    "                                      override_is_manager=override_is_manager, user_text=user_text)\n",
    "    intents = intent_persona(gate.get(\"intents\", []))\n",
    "\n",
    "    sections = {}\n",
    "    if \"job\" in intents:\n",
    "        sections[\"jobs\"] = job_reflexion(job_tool(user_text))\n",
    "    if \"courses\" in intents:\n",
    "        sections[\"courses\"] = courses_reflexion(courses_tool(user_text, state), state.is_manager)\n",
    "    if \"development_plan\" in intents:\n",
    "        ctx = tool_pg_search(\"development plan \" + (user_text or \"\"), 6)\n",
    "        sections[\"development_plan\"] = ctx[:5]\n",
    "    if \"manager_toolkit\" in intents:\n",
    "        ctx = tool_pg_search(\"manager coaching \" + (user_text or \"\"), 6)\n",
    "        sections[\"manager_toolkit\"] = ctx[:5]\n",
    "    if \"leadership_strategy\" in intents:\n",
    "        ctx = tool_pg_search(\"capability gaps portfolio \" + (user_text or \"\"), 6)\n",
    "        sections[\"leadership_strategy\"] = ctx[:5]\n",
    "\n",
    "    include_onboarding = not bool(profile_meta)\n",
    "    final = consolidation_summary(sections, include_onboarding=include_onboarding)\n",
    "    return {\n",
    "        \"blocked\": False,\n",
    "        \"gate\": gate,\n",
    "        \"state\": state,\n",
    "        \"profile_found\": bool(profile_meta),\n",
    "        \"sections\": sections,\n",
    "        \"answer\": final\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a4b76da",
   "metadata": {},
   "source": [
    "## 7) Smoke Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e522650",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "tests = [\n",
    "    (\"Reset my laptop password\", None, None, None, None),\n",
    "    (\"What jobs and courses should I look at for data engineering?\", None, None, None, False),\n",
    "    (\"What jobs and courses should I look at for data engineering?\", None, None, None, True),\n",
    "]\n",
    "\n",
    "for text, email, name, div, is_mgr in tests:\n",
    "    print(\"\\n---\\nQ:\", text, \"| override_is_manager:\", is_mgr)\n",
    "    out = run_workflow(text, email=email, name=name, division=div, override_is_manager=is_mgr)\n",
    "    if out.get(\"blocked\"):\n",
    "        print(\"BLOCKED:\", out[\"answer\"])\n",
    "    else:\n",
    "        display(Markdown(out[\"answer\"]))\n",
    "        print(\"intents:\", out[\"gate\"][\"intents\"], \"| is_manager:\", out[\"state\"].is_manager, \"| profile_found:\", out[\"profile_found\"])\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
